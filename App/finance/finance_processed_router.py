from fastapi import APIRouter, HTTPException
import pandas as pd
import os
from Database.mongodb_connection import mongo_db
from Preprocessor_Fdata.Preprocess_daily import run_process_daily
from Preprocessor_Fdata.Preprocess_ipostock import run_process_ipostock
from Preprocessor_Fdata.Preprocess_monthly import run_process_monthly
from pymongo import UpdateOne

# ğŸš€ FastAPI ë¼ìš°í„° ìƒì„±
router = APIRouter(
    prefix="/finance",
    tags=["finance"]
)

# ğŸ“Œ ì—…ë¡œë“œí•  ê¸ˆìœµ ë°ì´í„° ì»¬ë ‰ì…˜ ì„¤ì •
collections = {
    "IPOSTOCK": mongo_db.IPOSTOCK,  # ê³µëª¨ì£¼ ë°ì´í„° (ê¸°ì—…ëª… ê¸°ì¤€ ì €ì¥)
    "Finance_by_month": mongo_db.Finance_by_month,  # ì›”ë³„ ê¸ˆìœµ ë°ì´í„° (month_key + index ê¸°ì¤€ ì €ì¥)
    "Finance_by_date": mongo_db.Finance_by_date  # ì¼ë³„ ê¸ˆìœµ ë°ì´í„° (date ê¸°ì¤€ ì €ì¥)
}

# ğŸ“‚ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
data_files = {
    "IPOSTOCK": "Finance_data/X_stat.csv",
    "Finance_by_month": "Finance_data/df_monthly.csv",
    "Finance_by_date": "Finance_data/df_daily.csv"
}

# ğŸ¦ ì²˜ë¦¬í•  ì „ì²˜ë¦¬ í•¨ìˆ˜
preprocess_functions = {
    "IPOSTOCK": run_process_ipostock,
    "Finance_by_month": run_process_monthly,
    "Finance_by_date": run_process_daily
}


@router.post("/upload")
def upload_finance_data(load_from_json: bool = False):
    """
    ğŸ“‚ ê¸ˆìœµ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ê°€ê³µí•˜ì—¬ MongoDBì— ì €ì¥í•˜ëŠ” API.
    
    - `load_from_json=True` â†’ ë¡œì»¬ JSON ë°ì´í„° ì²˜ë¦¬ í›„ ì—…ë¡œë“œ
    - `load_from_json=False` â†’ ê¸°ì¡´ CSV ë°ì´í„° ë¡œë“œ í›„ ì—…ë¡œë“œ
    """
    response_summary = {}

    for collection_name, collection in collections.items():
        try:
            # âœ… JSON ë°ì´í„°ì—ì„œ ì§ì ‘ ì²˜ë¦¬
            if collection_name == "Finance_by_date" and load_from_json:
                json_dir = "Finance_data/etc"
                processed_df = run_process_daily(json_dir=json_dir)
            elif collection_name == "Finance_by_month" and load_from_json:
                json_dir = "Finance_data/etc"
                processed_df = run_process_monthly(json_dir=json_dir)
            elif collection_name == "IPOSTOCK" and load_from_json:
                input_json = "Finance_data/etc/IPOSTOCK_data.json"
                processed_df = run_process_ipostock(json_file=input_json)
            else:
                # âœ… CSV íŒŒì¼ ë¡œë“œ
                file_path = data_files[collection_name]
                processed_df = pd.read_csv(file_path, encoding="utf-8-sig")

                # âœ… ë°ì´í„° ê°€ê³µ (ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©)
                processed_df = preprocess_functions[collection_name](processed_df)

            # âœ… ì»¬ëŸ¼ ì˜ˆì™¸ ì²˜ë¦¬ (MongoDB `_id` ì„¤ì •)
            if collection_name == "Finance_by_date":
                if "date" not in processed_df.columns:
                    raise KeyError(f"âŒ {collection_name}: 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                processed_df["_id"] = processed_df["date"]  # âœ… ì¼ë³„ ë°ì´í„°ì˜ `_id`ëŠ” `date`

            elif collection_name == "Finance_by_month":
                if "month_key" not in processed_df.columns:
                    raise KeyError(f"âŒ {collection_name}: 'month_key' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

                # âœ… `_id`ë¥¼ `month_key` + indexë¡œ ì„¤ì •í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                processed_df["_id"] = processed_df["month_key"] # âœ… ì›”ë³„ ë°ì´í„°ì˜ `_id`ëŠ” `month_key`

            elif collection_name == "IPOSTOCK":
                if "ê¸°ì—…ëª…" not in processed_df.columns:
                    raise KeyError(f"âŒ {collection_name}: 'ê¸°ì—…ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                processed_df["_id"] = processed_df["ê¸°ì—…ëª…"]  # âœ… ê³µëª¨ì£¼ ë°ì´í„°ì˜ `_id`ëŠ” `ê¸°ì—…ëª…`

            # âœ… ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ì¤‘ë³µ ê°œìˆ˜ í™•ì¸
            total_records = len(processed_df)
            duplicate_count = 0
            inserted_count = 0

            bulk_operations = []
            for record in processed_df.to_dict("records"):
                record_id = record["_id"]  # `_id` ê°’ ë¶„ë¦¬
                update_data = {key: value for key, value in record.items() if key != "_id"}  # `_id` ì œê±°

                existing_doc = collection.find_one({"_id": record_id})

                if existing_doc:
                    duplicate_count += 1
                    bulk_operations.append(
                        UpdateOne(
                            {"_id": record_id},  # í•„í„°
                            {"$set": update_data},  # ì—…ë°ì´íŠ¸
                            upsert=True  # âœ… ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
                        )
                    )
                else:
                    inserted_count += 1
                    bulk_operations.append(
                        UpdateOne(
                            {"_id": record_id},  # í•„í„°
                            {"$set": update_data},  # ì—…ë°ì´íŠ¸
                            upsert=True  # âœ… ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
                        )
                    )

            # âœ… MongoDBì— ì¼ê´„ ì €ì¥ (Bulk Write ì‚¬ìš©)
            if bulk_operations:
                result = collection.bulk_write(bulk_operations)
                inserted_count = result.upserted_count
                duplicate_count = result.matched_count

            response_summary[collection_name] = {
                "total_records": total_records,
                "inserted": inserted_count,
                "updated": duplicate_count
            }

            print(f"âœ… {collection_name} ë°ì´í„° ì €ì¥ ì™„ë£Œ! (ì´: {total_records}ê°œ, ìƒˆ ë°ì´í„°: {inserted_count}ê°œ, ì—…ë°ì´íŠ¸: {duplicate_count}ê°œ)")

        except KeyError as ke:
            raise HTTPException(status_code=500, detail=f"âŒ ê¸ˆìœµ ë°ì´í„° ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(ke)}")

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"âŒ ê¸ˆìœµ ë°ì´í„° ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {repr(e)}")

    return {
        "message": "âœ… ê¸ˆìœµ ë°ì´í„° ì—…ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ!",
        "summary": response_summary
    }