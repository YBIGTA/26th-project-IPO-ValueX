import pandas as pd
import re
import numpy as np
from tqdm import tqdm 

# êµ­ê°€ëª… í•œì ë³€í™˜ ë”•ì…”ë„ˆë¦¬
hanja_to_country = {
    "ç¾": "ë¯¸êµ­", "è»": "êµ°ëŒ€", "æ—¥": "ì¼ë³¸","ä¸­": "ì¤‘êµ­", "è‹±": "ì˜êµ­", "äº": "ì•„ì‹œì•„",
    "ç¨": "ë…ì¼", "ä½›": "í”„ë‘ìŠ¤", "åŠ ": "ìºë‚˜ë‹¤", "éœ²": "ëŸ¬ì‹œì•„", "å°": "ì¸ë„",
    "è¥¿": "ìŠ¤í˜ì¸", "æ¿ ": "í˜¸ì£¼", "éŸ“": "í•œêµ­", "åŒ—": "ë¶í•œ", "å—": "ë‚¨í•œ",
    "æ¸¯": "í™ì½©", "å°": "ëŒ€ë§Œ", "æ–°": "ì‹±ê°€í¬ë¥´", "è¶Š": "ë² íŠ¸ë‚¨", "æ³°": "íƒœêµ­"
}

#------------------------------------------------------------------------------------------------
# ë‚´ìš©ì´ ì—†ê±°ë‚˜ ë‚˜ì—´ì‹ ë³¸ë¬¸ NaNìœ¼ë¡œ ë³€í™˜

def delete_body(df):
    """
    íŠ¹ì • íŒ¨í„´ì„ í¬í•¨í•˜ëŠ” ì œëª©ì˜ ë³¸ë¬¸(Body)ì„ NaNìœ¼ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜.

    1. ì œëª©ì´ `[ê³µì‹œ]`, `[ìœ ê°€ê³µì‹œ]`, `[ì •ì •ê³µì‹œ]` ë“± `[ ]` ì•ˆì— "ê³µì‹œ"ê°€ í¬í•¨ë˜ë©´ ì‚­ì œ
    2. ì œëª©ì´ `[ì¸ì‚¬]`ë¡œ ì‹œì‘í•˜ë©´ ì‚­ì œ
    3. ì œëª©ì´ `[í‘œ]`ë¡œ ì‹œì‘í•˜ë©´ ì‚­ì œ
    4. ì œëª©ì´ `[ì˜¤ëŠ˜ì˜ ë©”ëª¨]`ë¡œ ì‹œì‘í•˜ë©´ ì‚­ì œ
    5. ì œëª©ì´ `[ì£¼ê°„ì¶”ì²œì£¼]`ë¡œ ì‹œì‘í•˜ë©´ ì‚­ì œ
    6. ì œëª©ì´ "ì¢…ëª©ë‰´ìŠ¤"ë¡œ ëë‚˜ë©´ ì‚­ì œ

    :param df: ì²˜ë¦¬í•  DataFrame
    :return: ë³¸ë¬¸ì„ ìˆ˜ì •í•œ DataFrame
    """

    # ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
    pattern_public_notice = r"^\[.*ê³µì‹œ.*\]"  
    pattern_personnel_notice = r"^\[ì¸ì‚¬\]"  
    pattern_table_notice = r"^\[í‘œ\]"  
    pattern_today_memo = r"^\[ì˜¤ëŠ˜ì˜ ë©”ëª¨\]"  
    pattern_weekly_recommendation = r"^\[ì£¼ê°„ì¶”ì²œì£¼\]"  
    pattern_stock_news = r"ì¢…ëª©ë‰´ìŠ¤$"  

    # íŠ¹ì • íŒ¨í„´ì„ í¬í•¨í•˜ëŠ” ì œëª©ì˜ Bodyë¥¼ NaNìœ¼ë¡œ ë³€ê²½
    df = df.copy()
    df.loc[df["Title"].str.match(pattern_public_notice, na=False), "Body_processed"] = np.nan
    df.loc[df["Title"].str.match(pattern_personnel_notice, na=False), "Body_processed"] = np.nan
    df.loc[df["Title"].str.match(pattern_table_notice, na=False), "Body_processed"] = np.nan
    df.loc[df["Title"].str.match(pattern_today_memo, na=False), "Body_processed"] = np.nan
    df.loc[df["Title"].str.match(pattern_weekly_recommendation, na=False), "Body_processed"] = np.nan
    df.loc[df["Title"].str.endswith("ì¢…ëª©ë‰´ìŠ¤", na=False), "Body_processed"] = np.nan

    return df

#------------------------------------------------------------------------------------------------
#  ê´‘ê³ ê¸€ ì‚­ì œ

def remove_advertisements(df):
    """
    1. ì œëª©(Title)ê³¼ ë³¸ë¬¸(Body)ì— íŠ¹ì • í‚¤ì›Œë“œ(ê¸‰ë“±ì£¼, í…Œë§ˆ, ì¢…ëª©)ê°€ ëª¨ë‘ í¬í•¨ë˜ë©´ í•´ë‹¹ í–‰ì„ ì‚­ì œ.
    2. ë³¸ë¬¸(Body)ì— "â—† ìƒˆí•´ ë§ˆì¼“ë ˆì´ë”ê°€ ë‹¤ì–‘í•´ì§‘ë‹ˆë‹¤â€¦" ì´í›„ì˜ ëª¨ë“  ë‚´ìš©ì„ ì‚­ì œ.
    3. NaN ê°’ì€ ìœ ì§€í•˜ë©° ì²˜ë¦¬.

    :param df: ì²˜ë¦¬í•  DataFrame
    :return: ê´‘ê³  ê²Œì‹œê¸€ì„ NaN ë˜ëŠ” ë³¸ë¬¸ ì¼ë¶€ ì œê±°í•œ DataFrame
    """
    # ê´‘ê³ ì„± í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    ad_keywords = ["ê¸‰ë“±ì£¼", "í…Œë§ˆ", "ì¢…ëª©"]
    
    # ê´‘ê³ ì„± í‚¤ì›Œë“œê°€ ëª¨ë‘ í¬í•¨ëœ í–‰ ì°¾ê¸°
    mask = df["Title"].astype(str).str.contains(ad_keywords[0], na=False) & \
           df["Title"].astype(str).str.contains(ad_keywords[1], na=False) & \
           df["Title"].astype(str).str.contains(ad_keywords[2], na=False)

    mask |= df["Body"].astype(str).str.contains(ad_keywords[0], na=False) & \
            df["Body"].astype(str).str.contains(ad_keywords[1], na=False) & \
            df["Body"].astype(str).str.contains(ad_keywords[2], na=False)

    # ê´‘ê³ ì„± í‚¤ì›Œë“œ í¬í•¨ëœ í–‰ì„ NaNìœ¼ë¡œ ë³€ê²½ (í•˜ì§€ë§Œ ê¸°ì¡´ NaNì€ ìœ ì§€)
    df = df.copy()
    df.loc[mask, ["Title", "Body_processed"]] = np.nan

    # ë³¸ë¬¸ì—ì„œ "â—† ìƒˆí•´ ë§ˆì¼“ë ˆì´ë”ê°€ ë‹¤ì–‘í•´ì§‘ë‹ˆë‹¤â€¦" ì´í›„ ë‚´ìš© ì‚­ì œ (NaN ê°’ì€ ìœ ì§€)
    df.loc[:, "Body_processed"] = df["Body"].astype(str).apply(lambda x: re.sub(r"â—† ìƒˆí•´ ë§ˆì¼“ë ˆì´ë”ê°€ ë‹¤ì–‘í•´ì§‘ë‹ˆë‹¤â€¦.*", "", x) if x != "nan" else x)

    return df

#------------------------------------------------------------------------------------------------
#  í•œì ë³€í™˜

def convert_hanja(text):
    """ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í•œìë¡œ í‘œí˜„ëœ êµ­ê°€ëª…ì„ í•œê¸€ë¡œ ë³€í™˜"""
    if not isinstance(text, str):  
        return text  # ì›ë˜ ê°’ ë°˜í™˜ (NaN ë˜ëŠ” ìˆ«ìì¸ ê²½ìš°)

    # ê¸°ë³¸ ë³€í™˜ (ç¾ â†’ ë¯¸êµ­, è» â†’ êµ°ëŒ€ ë“±)
    for hanja, korean in hanja_to_country.items():
        text = text.replace(hanja, korean)

    # # "ä¸­" ë³€í™˜ (ë¬¸ë§¥ ê³ ë ¤: "ì¤‘êµ­"ì´ í¬í•¨ëœ ê²½ìš°ë§Œ ë³€í™˜)
    # if "ì¤‘êµ­" in text:
    #     text = re.sub(r"ä¸­(?=.*ì¤‘êµ­)(?!\.$)", "ì¤‘êµ­", text)

    return text

#------------------------------------------------------------------------------------------------
#  ì“¸ë° ì—†ëŠ” ë‚´ìš© ì‚­ì œ

def preprocess_body(text):
    if not isinstance(text, str):  
        return text  # ì›ë˜ ê°’ ë°˜í™˜ (NaN ë˜ëŠ” ìˆ«ìì¸ ê²½ìš°)
    
    text_cleaned = text

    # 1ï¸ â“’ í¬í•¨ëœ í–‰ê³¼ ê·¸ ì´í›„ ëª¨ë“  í–‰ ì‚­ì œ
    text_cleaned = re.sub(r"â“’.*", "â“’", text_cleaned)  # â“’ ì´í›„ ëª¨ë“  ë‚´ìš© â†’ â“’ë§Œ ë‚¨ê¸°ê¸°
    text_cleaned = text_cleaned.split("\n")  # ì¤„ ë‹¨ìœ„ë¡œ ë¶„í• 
    text_cleaned = "\n".join(line for line in text_cleaned if "â“’" not in line)  # â“’ê°€ í¬í•¨ëœ í–‰ ì‚­ì œ

    # 2ï¸ [] í˜•íƒœì˜ ê¸€ ëª¨ë‘ ì‚­ì œ (ì–¸ë¡ ì‚¬, ì¶”ì²œ, ì´ë¯¸ì§€ ì¶œì²˜ ë“±)
    text_cleaned = re.sub(r"\[.*?\]", "", text_cleaned)

    # 3ï¸ @ê°€ í¬í•¨ëœ í–‰ ì‚­ì œ
    text_cleaned = "\n".join([line for line in text_cleaned.split("\n") if "@" not in line])

    # 4ï¸ "ê¸°ì"ë¡œ ëë‚˜ëŠ” í–‰ ì‚­ì œ
    text_cleaned = "\n".join([line for line in text_cleaned.split("\n") if not re.search(r"(\sê¸°ì\s|ê¸°ì$)", line)])

    # 5ï¸ **"/" ì´í›„ ê¸°ìì´ë¦„ + 'ê¸°ì'ë¡œ ëë‚˜ëŠ” í–‰ ì‚­ì œ** 
    text_cleaned = "\n".join([line for line in text_cleaned.split("\n") if not re.search(r"/\s*[ê°€-í£]+\s*ê¸°ì$", line)])

    # 6ï¸ íŠ¹ì • íŒ¨í„´ì„ í¬í•¨í•˜ëŠ” ë¬¸ì¥ ìì²´ ì‚­ì œ
    remove_patterns = [
        r"â–¶.*",  # â–¶ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ë¬¸ì¥ ì‚­ì œ
        r"â˜.*",  # â˜ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì‚­ì œ
        r"ã€.*?ã€‘",  # ã€ ì•µì»¤ë©˜íŠ¸ ã€‘ ë“± ì‚­ì œ
        r".*? ê¸°ìì…ë‹ˆë‹¤\.",  # "000 ê¸°ìì…ë‹ˆë‹¤." ì‚­ì œ
        r".*? ê¸°ìê°€ ì·¨ì¬í–ˆìŠµë‹ˆë‹¤\.",  # "000 ê¸°ìê°€ ì·¨ì¬í–ˆìŠµë‹ˆë‹¤." ì‚­ì œ
        r".*? ì¶”ì²œ$",  # "ì¶”ì²œ"ìœ¼ë¡œ ëë‚˜ëŠ” ë¬¸ì¥ ì‚­ì œ
        r".*? ì´ ê¸°ì‚¬ëŠ” .*",  # "ì´ ê¸°ì‚¬ëŠ” ~" ë¬¸ì¥ ì „ì²´ ì‚­ì œ
        r".*? ì‚¬ì§„ì œê³µ=.*",  # "ì‚¬ì§„ì œê³µ" í¬í•¨ëœ ì¤„ ì‚­ì œ
        r".*? ê·¸ë˜í”½.*",  # "[ê·¸ë˜í”½]" í¬í•¨ëœ ì¤„ ì‚­ì œ
        r"ì‚¬ì§„\s*=",  # "ì‚¬ì§„ =" ì‚­ì œ
        r"\(ì´í•˜ .*?\)",  # "(ì´í•˜ ~)" íŒ¨í„´ ì‚­ì œ
        r"í•œêµ­ê²½ì œ|í•œê²½ë¡œë³´ë‰´ìŠ¤",  # "í•œêµ­ê²½ì œ"ì™€ "í•œê²½ë¡œë³´ë‰´ìŠ¤" ì‚­ì œ
        r"ìˆœë§¤ìˆ˜ ìƒìœ„ ì¢…ëª©\s*\n\n",  # "ìˆœë§¤ìˆ˜ ìƒìœ„ ì¢…ëª©"ì´ ë‹¨ë…ìœ¼ë¡œ ìˆê³  \n\n ìˆëŠ” ê²½ìš° ì‚­ì œ
        r"ìˆœë§¤ë„ ìƒìœ„ ì¢…ëª©\s*\n\n",  # "ìˆœë§¤ë„ ìƒìœ„ ì¢…ëª©"ì´ ë‹¨ë…ìœ¼ë¡œ ìˆê³  \n\n ìˆëŠ” ê²½ìš° ì‚­ì œ
        r"ìŠ¤í†¡ë´‡ ê¸°ì.*",  # "ìŠ¤í†¡ë´‡ ê¸°ì" í¬í•¨ ì´í›„ ëª¨ë“  ì¤„ ì‚­ì œ
        r"!\[image.*\]\(attachment:.*?\)",  # "[image.png](attachment:..)" ê°™ì€ ì´ë¯¸ì§€ ì²¨ë¶€ íƒœê·¸ ì‚­ì œ
    ]
    for pattern in remove_patterns:
        text_cleaned = re.sub(pattern, "", text_cleaned)

    # 7 **ì¸í„°ë·° ê´€ë ¨ ë¬¸ì¥ ì‚­ì œ (â–¶ ì¸í„°ë·° : ... ë‹¤ìŒ ì¤„ë„ ì‚­ì œ)**
    lines = text_cleaned.split("\n")
    filtered_lines = []
    skip_next = False  # ì¸í„°ë·° ë‹¤ìŒ ì¤„ë„ ì‚­ì œí•˜ê¸° ìœ„í•œ í”Œë˜ê·¸

    for line in lines:
        if "â–¶ ì¸í„°ë·° :" in line:
            skip_next = True  # ë‹¤ìŒ ì¤„ë„ ì‚­ì œí•´ì•¼ í•¨
            continue
        if skip_next:
            skip_next = False
            continue  # ì¸í„°ë·° ë‹¤ìŒ ì¤„ë„ ì‚­ì œ
        filtered_lines.append(line)

    text_cleaned = "\n".join(filtered_lines)

    # 8ï¸ **8ë‹¨ì–´ ë¯¸ë§Œì¸ë° ë¬¸ì¥ ëì— '.' ì—†ìœ¼ë©´ í–‰ ì‚­ì œ**
    lines = text_cleaned.split("\n")
    text_cleaned = "\n".join(
        line for line in lines if len(line.split()) >= 8 or line.strip().endswith(".")
    )

    # 9ï¸ **ì „ì²´ ë³¸ë¬¸ ì •ì œ í›„ ë‹¨ì–´ ê°œìˆ˜ê°€ 20ê°œ ë¯¸ë§Œì´ë©´ NaN ì²˜ë¦¬**
    word_count = len(text_cleaned.split())
    if word_count < 20:
        return np.nan  # NaN ê°’ ì²˜ë¦¬

    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text_cleaned = re.sub(r"\s{2,}", " ", text_cleaned).strip()

    return text_cleaned

#------------------------------------------------------------------------------------------------
#  íŠ¹ìˆ˜ë¬¸ì ì œê±°

def remove_special_characters(text):
    """íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    if not isinstance(text, str):  
        return text  # NaN ë˜ëŠ” ìˆ«ìì¸ ê²½ìš° ì›ë˜ ê°’ ë°˜í™˜
    
    return re.sub(r"[^\w\s]", "", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°


def run_preprocess_naver(input_df):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬ í›„ ì €ì¥"""
    try:
        df = input_df
        df = df.copy()

        df["Body_processed"] = df["Body"]

        # ì œëª© ë° ê´‘ê³ ì„± ë¬¸êµ¬ ì²˜ë¦¬
        print("ğŸš€ ì œëª© ë° ê´‘ê³ ì„± ë¬¸êµ¬ í•„í„°ë§ ì¤‘...")
        df = delete_body(df)
        df = remove_advertisements(df)

        # âœ… tqdmì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ progress barë¡œ ì ìš©
        print("ğŸš€ ë³¸ë¬¸ ì „ì²˜ë¦¬ ì¤‘...")
        with tqdm(total=len(df), desc="ğŸ“„ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì§„í–‰") as pbar:
            for index, row in df.iterrows():
                processed_text = row["Body_processed"]
                processed_text = convert_hanja(processed_text)
                processed_text = preprocess_body(processed_text)
                processed_text = remove_special_characters(processed_text)

                df.at[index, "Body_processed"] = processed_text
                pbar.update(1)  # âœ… í•œ ë‹¨ê³„ ì™„ë£Œ í›„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸

        return df

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")