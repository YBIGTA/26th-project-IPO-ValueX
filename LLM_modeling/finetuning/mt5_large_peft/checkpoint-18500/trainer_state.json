{
  "best_metric": 1.1852672100067139,
  "best_model_checkpoint": "./mt5_large_peft\\checkpoint-18500",
  "epoch": 1.885254254560277,
  "eval_steps": 500,
  "global_step": 18500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010190563538163661,
      "grad_norm": 27453.126953125,
      "learning_rate": 2.9898094364618364e-05,
      "loss": 28.2202,
      "step": 100
    },
    {
      "epoch": 0.020381127076327322,
      "grad_norm": 6308.0859375,
      "learning_rate": 2.9796188729236727e-05,
      "loss": 27.3786,
      "step": 200
    },
    {
      "epoch": 0.03057169061449098,
      "grad_norm": 2764.48779296875,
      "learning_rate": 2.969428309385509e-05,
      "loss": 24.3512,
      "step": 300
    },
    {
      "epoch": 0.040762254152654644,
      "grad_norm": 5947.34814453125,
      "learning_rate": 2.9592377458473454e-05,
      "loss": 20.3978,
      "step": 400
    },
    {
      "epoch": 0.0509528176908183,
      "grad_norm": 3450.567626953125,
      "learning_rate": 2.9490471823091817e-05,
      "loss": 19.3209,
      "step": 500
    },
    {
      "epoch": 0.0509528176908183,
      "eval_loss": 13.17918872833252,
      "eval_runtime": 164.9778,
      "eval_samples_per_second": 20.997,
      "eval_steps_per_second": 10.498,
      "step": 500
    },
    {
      "epoch": 0.06114338122898196,
      "grad_norm": 281.2143249511719,
      "learning_rate": 2.938856618771018e-05,
      "loss": 15.881,
      "step": 600
    },
    {
      "epoch": 0.07133394476714562,
      "grad_norm": 4795.501953125,
      "learning_rate": 2.9286660552328544e-05,
      "loss": 14.4896,
      "step": 700
    },
    {
      "epoch": 0.08152450830530929,
      "grad_norm": 3667.901123046875,
      "learning_rate": 2.9184754916946907e-05,
      "loss": 12.2237,
      "step": 800
    },
    {
      "epoch": 0.09171507184347294,
      "grad_norm": 202.11444091796875,
      "learning_rate": 2.908284928156527e-05,
      "loss": 9.8659,
      "step": 900
    },
    {
      "epoch": 0.1019056353816366,
      "grad_norm": 72.45142364501953,
      "learning_rate": 2.8980943646183638e-05,
      "loss": 8.5164,
      "step": 1000
    },
    {
      "epoch": 0.1019056353816366,
      "eval_loss": 5.212243556976318,
      "eval_runtime": 164.7978,
      "eval_samples_per_second": 21.02,
      "eval_steps_per_second": 10.51,
      "step": 1000
    },
    {
      "epoch": 0.11209619891980027,
      "grad_norm": 15.142948150634766,
      "learning_rate": 2.8879038010801997e-05,
      "loss": 6.0471,
      "step": 1100
    },
    {
      "epoch": 0.12228676245796392,
      "grad_norm": 3.3956282138824463,
      "learning_rate": 2.877713237542036e-05,
      "loss": 3.2172,
      "step": 1200
    },
    {
      "epoch": 0.13247732599612758,
      "grad_norm": 2.6316514015197754,
      "learning_rate": 2.8675226740038724e-05,
      "loss": 2.5159,
      "step": 1300
    },
    {
      "epoch": 0.14266788953429124,
      "grad_norm": 3.639423370361328,
      "learning_rate": 2.8573321104657087e-05,
      "loss": 2.2805,
      "step": 1400
    },
    {
      "epoch": 0.1528584530724549,
      "grad_norm": 3.6864843368530273,
      "learning_rate": 2.847141546927545e-05,
      "loss": 2.04,
      "step": 1500
    },
    {
      "epoch": 0.1528584530724549,
      "eval_loss": 1.5683362483978271,
      "eval_runtime": 175.8535,
      "eval_samples_per_second": 19.698,
      "eval_steps_per_second": 9.849,
      "step": 1500
    },
    {
      "epoch": 0.16304901661061857,
      "grad_norm": 8.59614086151123,
      "learning_rate": 2.8369509833893818e-05,
      "loss": 2.1247,
      "step": 1600
    },
    {
      "epoch": 0.17323958014878224,
      "grad_norm": 2.726902961730957,
      "learning_rate": 2.8267604198512178e-05,
      "loss": 1.909,
      "step": 1700
    },
    {
      "epoch": 0.18343014368694588,
      "grad_norm": 5.7329864501953125,
      "learning_rate": 2.816569856313054e-05,
      "loss": 1.8978,
      "step": 1800
    },
    {
      "epoch": 0.19362070722510955,
      "grad_norm": 2.2479844093322754,
      "learning_rate": 2.8063792927748904e-05,
      "loss": 1.8325,
      "step": 1900
    },
    {
      "epoch": 0.2038112707632732,
      "grad_norm": 2.9731550216674805,
      "learning_rate": 2.7961887292367268e-05,
      "loss": 1.8252,
      "step": 2000
    },
    {
      "epoch": 0.2038112707632732,
      "eval_loss": 1.4640119075775146,
      "eval_runtime": 182.7855,
      "eval_samples_per_second": 18.951,
      "eval_steps_per_second": 9.476,
      "step": 2000
    },
    {
      "epoch": 0.21400183430143688,
      "grad_norm": 5.605309009552002,
      "learning_rate": 2.785998165698563e-05,
      "loss": 1.8403,
      "step": 2100
    },
    {
      "epoch": 0.22419239783960054,
      "grad_norm": 2.940595865249634,
      "learning_rate": 2.7758076021603998e-05,
      "loss": 1.7635,
      "step": 2200
    },
    {
      "epoch": 0.23438296137776418,
      "grad_norm": 2.7001793384552,
      "learning_rate": 2.765617038622236e-05,
      "loss": 1.8404,
      "step": 2300
    },
    {
      "epoch": 0.24457352491592785,
      "grad_norm": 2.429716110229492,
      "learning_rate": 2.755426475084072e-05,
      "loss": 1.7498,
      "step": 2400
    },
    {
      "epoch": 0.2547640884540915,
      "grad_norm": 3.242645740509033,
      "learning_rate": 2.7452359115459084e-05,
      "loss": 1.8226,
      "step": 2500
    },
    {
      "epoch": 0.2547640884540915,
      "eval_loss": 1.4022103548049927,
      "eval_runtime": 188.2106,
      "eval_samples_per_second": 18.405,
      "eval_steps_per_second": 9.202,
      "step": 2500
    },
    {
      "epoch": 0.26495465199225515,
      "grad_norm": 3.6384782791137695,
      "learning_rate": 2.7350453480077448e-05,
      "loss": 1.7999,
      "step": 2600
    },
    {
      "epoch": 0.2751452155304188,
      "grad_norm": 2.0548856258392334,
      "learning_rate": 2.724854784469581e-05,
      "loss": 1.8131,
      "step": 2700
    },
    {
      "epoch": 0.2853357790685825,
      "grad_norm": 3.25698184967041,
      "learning_rate": 2.7146642209314178e-05,
      "loss": 1.6744,
      "step": 2800
    },
    {
      "epoch": 0.29552634260674615,
      "grad_norm": 3.2758820056915283,
      "learning_rate": 2.704473657393254e-05,
      "loss": 1.7561,
      "step": 2900
    },
    {
      "epoch": 0.3057169061449098,
      "grad_norm": 2.1602401733398438,
      "learning_rate": 2.6942830938550904e-05,
      "loss": 1.6305,
      "step": 3000
    },
    {
      "epoch": 0.3057169061449098,
      "eval_loss": 1.38109290599823,
      "eval_runtime": 194.9073,
      "eval_samples_per_second": 17.773,
      "eval_steps_per_second": 8.886,
      "step": 3000
    },
    {
      "epoch": 0.3159074696830735,
      "grad_norm": 4.970451354980469,
      "learning_rate": 2.6840925303169264e-05,
      "loss": 1.6063,
      "step": 3100
    },
    {
      "epoch": 0.32609803322123715,
      "grad_norm": 3.5661942958831787,
      "learning_rate": 2.6739019667787628e-05,
      "loss": 1.7028,
      "step": 3200
    },
    {
      "epoch": 0.3362885967594008,
      "grad_norm": 3.0770022869110107,
      "learning_rate": 2.663711403240599e-05,
      "loss": 1.6922,
      "step": 3300
    },
    {
      "epoch": 0.3464791602975645,
      "grad_norm": 9.248029708862305,
      "learning_rate": 2.6535208397024358e-05,
      "loss": 1.6022,
      "step": 3400
    },
    {
      "epoch": 0.3566697238357281,
      "grad_norm": 4.056350231170654,
      "learning_rate": 2.643330276164272e-05,
      "loss": 1.7081,
      "step": 3500
    },
    {
      "epoch": 0.3566697238357281,
      "eval_loss": 1.358703851699829,
      "eval_runtime": 197.1859,
      "eval_samples_per_second": 17.567,
      "eval_steps_per_second": 8.784,
      "step": 3500
    },
    {
      "epoch": 0.36686028737389176,
      "grad_norm": 4.463601112365723,
      "learning_rate": 2.6331397126261084e-05,
      "loss": 1.6415,
      "step": 3600
    },
    {
      "epoch": 0.3770508509120554,
      "grad_norm": 1.8606330156326294,
      "learning_rate": 2.6229491490879444e-05,
      "loss": 1.6281,
      "step": 3700
    },
    {
      "epoch": 0.3872414144502191,
      "grad_norm": 3.250900983810425,
      "learning_rate": 2.6127585855497808e-05,
      "loss": 1.6821,
      "step": 3800
    },
    {
      "epoch": 0.39743197798838276,
      "grad_norm": 3.322420597076416,
      "learning_rate": 2.602568022011617e-05,
      "loss": 1.6299,
      "step": 3900
    },
    {
      "epoch": 0.4076225415265464,
      "grad_norm": 2.563308000564575,
      "learning_rate": 2.5923774584734538e-05,
      "loss": 1.684,
      "step": 4000
    },
    {
      "epoch": 0.4076225415265464,
      "eval_loss": 1.3363786935806274,
      "eval_runtime": 196.3734,
      "eval_samples_per_second": 17.64,
      "eval_steps_per_second": 8.82,
      "step": 4000
    },
    {
      "epoch": 0.4178131050647101,
      "grad_norm": 2.463371515274048,
      "learning_rate": 2.58218689493529e-05,
      "loss": 1.6033,
      "step": 4100
    },
    {
      "epoch": 0.42800366860287375,
      "grad_norm": 29.73354148864746,
      "learning_rate": 2.5719963313971264e-05,
      "loss": 1.633,
      "step": 4200
    },
    {
      "epoch": 0.4381942321410374,
      "grad_norm": 3.0809860229492188,
      "learning_rate": 2.5618057678589628e-05,
      "loss": 1.6004,
      "step": 4300
    },
    {
      "epoch": 0.4483847956792011,
      "grad_norm": 2.6930699348449707,
      "learning_rate": 2.5516152043207988e-05,
      "loss": 1.6562,
      "step": 4400
    },
    {
      "epoch": 0.4585753592173647,
      "grad_norm": 2.620406150817871,
      "learning_rate": 2.541424640782635e-05,
      "loss": 1.5907,
      "step": 4500
    },
    {
      "epoch": 0.4585753592173647,
      "eval_loss": 1.3071873188018799,
      "eval_runtime": 196.574,
      "eval_samples_per_second": 17.622,
      "eval_steps_per_second": 8.811,
      "step": 4500
    },
    {
      "epoch": 0.46876592275552836,
      "grad_norm": 2.7053122520446777,
      "learning_rate": 2.5312340772444718e-05,
      "loss": 1.586,
      "step": 4600
    },
    {
      "epoch": 0.47895648629369203,
      "grad_norm": 2.8677291870117188,
      "learning_rate": 2.521043513706308e-05,
      "loss": 1.5709,
      "step": 4700
    },
    {
      "epoch": 0.4891470498318557,
      "grad_norm": 2.8104186058044434,
      "learning_rate": 2.5108529501681444e-05,
      "loss": 1.5965,
      "step": 4800
    },
    {
      "epoch": 0.49933761337001936,
      "grad_norm": 2.296156167984009,
      "learning_rate": 2.5006623866299808e-05,
      "loss": 1.5657,
      "step": 4900
    },
    {
      "epoch": 0.509528176908183,
      "grad_norm": 3.4835751056671143,
      "learning_rate": 2.490471823091817e-05,
      "loss": 1.6203,
      "step": 5000
    },
    {
      "epoch": 0.509528176908183,
      "eval_loss": 1.304913878440857,
      "eval_runtime": 197.8511,
      "eval_samples_per_second": 17.508,
      "eval_steps_per_second": 8.754,
      "step": 5000
    },
    {
      "epoch": 0.5197187404463467,
      "grad_norm": 1.97618567943573,
      "learning_rate": 2.480281259553653e-05,
      "loss": 1.556,
      "step": 5100
    },
    {
      "epoch": 0.5299093039845103,
      "grad_norm": 2.2320876121520996,
      "learning_rate": 2.4700906960154898e-05,
      "loss": 1.5569,
      "step": 5200
    },
    {
      "epoch": 0.540099867522674,
      "grad_norm": 2.9004650115966797,
      "learning_rate": 2.459900132477326e-05,
      "loss": 1.6221,
      "step": 5300
    },
    {
      "epoch": 0.5502904310608376,
      "grad_norm": 4.157751083374023,
      "learning_rate": 2.4497095689391624e-05,
      "loss": 1.5728,
      "step": 5400
    },
    {
      "epoch": 0.5604809945990014,
      "grad_norm": 7.6900200843811035,
      "learning_rate": 2.4395190054009988e-05,
      "loss": 1.6044,
      "step": 5500
    },
    {
      "epoch": 0.5604809945990014,
      "eval_loss": 1.2923901081085205,
      "eval_runtime": 195.7085,
      "eval_samples_per_second": 17.7,
      "eval_steps_per_second": 8.85,
      "step": 5500
    },
    {
      "epoch": 0.570671558137165,
      "grad_norm": 2.8713998794555664,
      "learning_rate": 2.429328441862835e-05,
      "loss": 1.5075,
      "step": 5600
    },
    {
      "epoch": 0.5808621216753287,
      "grad_norm": 2.7488250732421875,
      "learning_rate": 2.419137878324671e-05,
      "loss": 1.5439,
      "step": 5700
    },
    {
      "epoch": 0.5910526852134923,
      "grad_norm": 2.2639999389648438,
      "learning_rate": 2.4089473147865078e-05,
      "loss": 1.558,
      "step": 5800
    },
    {
      "epoch": 0.6012432487516559,
      "grad_norm": 37.6833610534668,
      "learning_rate": 2.398756751248344e-05,
      "loss": 1.5405,
      "step": 5900
    },
    {
      "epoch": 0.6114338122898196,
      "grad_norm": 3.5379674434661865,
      "learning_rate": 2.3885661877101804e-05,
      "loss": 1.668,
      "step": 6000
    },
    {
      "epoch": 0.6114338122898196,
      "eval_loss": 1.2729147672653198,
      "eval_runtime": 195.9285,
      "eval_samples_per_second": 17.68,
      "eval_steps_per_second": 8.84,
      "step": 6000
    },
    {
      "epoch": 0.6216243758279832,
      "grad_norm": 2.1992745399475098,
      "learning_rate": 2.3783756241720168e-05,
      "loss": 1.5117,
      "step": 6100
    },
    {
      "epoch": 0.631814939366147,
      "grad_norm": 3.0455079078674316,
      "learning_rate": 2.368185060633853e-05,
      "loss": 1.5144,
      "step": 6200
    },
    {
      "epoch": 0.6420055029043106,
      "grad_norm": 9.293886184692383,
      "learning_rate": 2.3579944970956894e-05,
      "loss": 1.577,
      "step": 6300
    },
    {
      "epoch": 0.6521960664424743,
      "grad_norm": 4.486127853393555,
      "learning_rate": 2.3478039335575258e-05,
      "loss": 1.52,
      "step": 6400
    },
    {
      "epoch": 0.6623866299806379,
      "grad_norm": 2.36458683013916,
      "learning_rate": 2.337613370019362e-05,
      "loss": 1.4031,
      "step": 6500
    },
    {
      "epoch": 0.6623866299806379,
      "eval_loss": 1.2933416366577148,
      "eval_runtime": 197.7927,
      "eval_samples_per_second": 17.513,
      "eval_steps_per_second": 8.757,
      "step": 6500
    },
    {
      "epoch": 0.6725771935188016,
      "grad_norm": 1.905340313911438,
      "learning_rate": 2.3274228064811984e-05,
      "loss": 1.6044,
      "step": 6600
    },
    {
      "epoch": 0.6827677570569652,
      "grad_norm": 2.296320676803589,
      "learning_rate": 2.3172322429430348e-05,
      "loss": 1.4941,
      "step": 6700
    },
    {
      "epoch": 0.692958320595129,
      "grad_norm": 3.882049560546875,
      "learning_rate": 2.307041679404871e-05,
      "loss": 1.6335,
      "step": 6800
    },
    {
      "epoch": 0.7031488841332926,
      "grad_norm": 2.8761281967163086,
      "learning_rate": 2.2968511158667074e-05,
      "loss": 1.6041,
      "step": 6900
    },
    {
      "epoch": 0.7133394476714562,
      "grad_norm": 2.7323718070983887,
      "learning_rate": 2.286660552328544e-05,
      "loss": 1.5593,
      "step": 7000
    },
    {
      "epoch": 0.7133394476714562,
      "eval_loss": 1.2611290216445923,
      "eval_runtime": 196.812,
      "eval_samples_per_second": 17.601,
      "eval_steps_per_second": 8.8,
      "step": 7000
    },
    {
      "epoch": 0.7235300112096199,
      "grad_norm": 4.449601173400879,
      "learning_rate": 2.27646998879038e-05,
      "loss": 1.5278,
      "step": 7100
    },
    {
      "epoch": 0.7337205747477835,
      "grad_norm": 2.6258163452148438,
      "learning_rate": 2.2662794252522164e-05,
      "loss": 1.611,
      "step": 7200
    },
    {
      "epoch": 0.7439111382859472,
      "grad_norm": 2.62459397315979,
      "learning_rate": 2.2560888617140528e-05,
      "loss": 1.5234,
      "step": 7300
    },
    {
      "epoch": 0.7541017018241108,
      "grad_norm": 4.098433494567871,
      "learning_rate": 2.245898298175889e-05,
      "loss": 1.5637,
      "step": 7400
    },
    {
      "epoch": 0.7642922653622746,
      "grad_norm": 2.9748430252075195,
      "learning_rate": 2.2357077346377254e-05,
      "loss": 1.5189,
      "step": 7500
    },
    {
      "epoch": 0.7642922653622746,
      "eval_loss": 1.2658799886703491,
      "eval_runtime": 196.8755,
      "eval_samples_per_second": 17.595,
      "eval_steps_per_second": 8.797,
      "step": 7500
    },
    {
      "epoch": 0.7744828289004382,
      "grad_norm": 2.6296234130859375,
      "learning_rate": 2.225517171099562e-05,
      "loss": 1.5699,
      "step": 7600
    },
    {
      "epoch": 0.7846733924386019,
      "grad_norm": 10.41512680053711,
      "learning_rate": 2.215326607561398e-05,
      "loss": 1.4323,
      "step": 7700
    },
    {
      "epoch": 0.7948639559767655,
      "grad_norm": 25.46101188659668,
      "learning_rate": 2.2051360440232344e-05,
      "loss": 1.4018,
      "step": 7800
    },
    {
      "epoch": 0.8050545195149291,
      "grad_norm": 2.717301607131958,
      "learning_rate": 2.1949454804850708e-05,
      "loss": 1.5025,
      "step": 7900
    },
    {
      "epoch": 0.8152450830530928,
      "grad_norm": 3.346304178237915,
      "learning_rate": 2.184754916946907e-05,
      "loss": 1.4063,
      "step": 8000
    },
    {
      "epoch": 0.8152450830530928,
      "eval_loss": 1.2586015462875366,
      "eval_runtime": 197.502,
      "eval_samples_per_second": 17.539,
      "eval_steps_per_second": 8.77,
      "step": 8000
    },
    {
      "epoch": 0.8254356465912565,
      "grad_norm": 2.2443106174468994,
      "learning_rate": 2.1745643534087435e-05,
      "loss": 1.5544,
      "step": 8100
    },
    {
      "epoch": 0.8356262101294202,
      "grad_norm": 4.1299591064453125,
      "learning_rate": 2.16437378987058e-05,
      "loss": 1.4979,
      "step": 8200
    },
    {
      "epoch": 0.8458167736675838,
      "grad_norm": 3.884678840637207,
      "learning_rate": 2.1541832263324165e-05,
      "loss": 1.4819,
      "step": 8300
    },
    {
      "epoch": 0.8560073372057475,
      "grad_norm": 4.754950523376465,
      "learning_rate": 2.1439926627942525e-05,
      "loss": 1.4972,
      "step": 8400
    },
    {
      "epoch": 0.8661979007439111,
      "grad_norm": 2.6721060276031494,
      "learning_rate": 2.1338020992560888e-05,
      "loss": 1.5716,
      "step": 8500
    },
    {
      "epoch": 0.8661979007439111,
      "eval_loss": 1.2622021436691284,
      "eval_runtime": 197.0185,
      "eval_samples_per_second": 17.582,
      "eval_steps_per_second": 8.791,
      "step": 8500
    },
    {
      "epoch": 0.8763884642820748,
      "grad_norm": 3.109265089035034,
      "learning_rate": 2.123611535717925e-05,
      "loss": 1.4233,
      "step": 8600
    },
    {
      "epoch": 0.8865790278202385,
      "grad_norm": 2.4745090007781982,
      "learning_rate": 2.1134209721797615e-05,
      "loss": 1.497,
      "step": 8700
    },
    {
      "epoch": 0.8967695913584022,
      "grad_norm": 3.1822710037231445,
      "learning_rate": 2.103230408641598e-05,
      "loss": 1.4493,
      "step": 8800
    },
    {
      "epoch": 0.9069601548965658,
      "grad_norm": 2.3245742321014404,
      "learning_rate": 2.0930398451034345e-05,
      "loss": 1.4934,
      "step": 8900
    },
    {
      "epoch": 0.9171507184347294,
      "grad_norm": 5.645829200744629,
      "learning_rate": 2.0828492815652708e-05,
      "loss": 1.5157,
      "step": 9000
    },
    {
      "epoch": 0.9171507184347294,
      "eval_loss": 1.2326971292495728,
      "eval_runtime": 198.5304,
      "eval_samples_per_second": 17.448,
      "eval_steps_per_second": 8.724,
      "step": 9000
    },
    {
      "epoch": 0.9273412819728931,
      "grad_norm": 3.431851387023926,
      "learning_rate": 2.0726587180271068e-05,
      "loss": 1.4571,
      "step": 9100
    },
    {
      "epoch": 0.9375318455110567,
      "grad_norm": 3.475478410720825,
      "learning_rate": 2.062468154488943e-05,
      "loss": 1.537,
      "step": 9200
    },
    {
      "epoch": 0.9477224090492204,
      "grad_norm": 3.1932883262634277,
      "learning_rate": 2.0522775909507795e-05,
      "loss": 1.4792,
      "step": 9300
    },
    {
      "epoch": 0.9579129725873841,
      "grad_norm": 3.1770684719085693,
      "learning_rate": 2.042087027412616e-05,
      "loss": 1.4273,
      "step": 9400
    },
    {
      "epoch": 0.9681035361255478,
      "grad_norm": 3.178551197052002,
      "learning_rate": 2.0318964638744525e-05,
      "loss": 1.4054,
      "step": 9500
    },
    {
      "epoch": 0.9681035361255478,
      "eval_loss": 1.2414758205413818,
      "eval_runtime": 197.9385,
      "eval_samples_per_second": 17.5,
      "eval_steps_per_second": 8.75,
      "step": 9500
    },
    {
      "epoch": 0.9782940996637114,
      "grad_norm": 2.45326828956604,
      "learning_rate": 2.0217059003362888e-05,
      "loss": 1.505,
      "step": 9600
    },
    {
      "epoch": 0.9884846632018751,
      "grad_norm": 2.089677572250366,
      "learning_rate": 2.0115153367981248e-05,
      "loss": 1.478,
      "step": 9700
    },
    {
      "epoch": 0.9986752267400387,
      "grad_norm": 4.328531742095947,
      "learning_rate": 2.001324773259961e-05,
      "loss": 1.4937,
      "step": 9800
    },
    {
      "epoch": 1.0088657902782023,
      "grad_norm": 2.9406490325927734,
      "learning_rate": 1.9911342097217975e-05,
      "loss": 1.526,
      "step": 9900
    },
    {
      "epoch": 1.019056353816366,
      "grad_norm": 2.572849988937378,
      "learning_rate": 1.980943646183634e-05,
      "loss": 1.4422,
      "step": 10000
    },
    {
      "epoch": 1.019056353816366,
      "eval_loss": 1.2440717220306396,
      "eval_runtime": 199.4125,
      "eval_samples_per_second": 17.371,
      "eval_steps_per_second": 8.686,
      "step": 10000
    },
    {
      "epoch": 1.0292469173545298,
      "grad_norm": 2.2916643619537354,
      "learning_rate": 1.9707530826454705e-05,
      "loss": 1.4889,
      "step": 10100
    },
    {
      "epoch": 1.0394374808926934,
      "grad_norm": 3.943711757659912,
      "learning_rate": 1.9605625191073068e-05,
      "loss": 1.5181,
      "step": 10200
    },
    {
      "epoch": 1.049628044430857,
      "grad_norm": 2.0316896438598633,
      "learning_rate": 1.950371955569143e-05,
      "loss": 1.4489,
      "step": 10300
    },
    {
      "epoch": 1.0598186079690206,
      "grad_norm": 2.2818784713745117,
      "learning_rate": 1.940181392030979e-05,
      "loss": 1.4468,
      "step": 10400
    },
    {
      "epoch": 1.0700091715071844,
      "grad_norm": 4.600247383117676,
      "learning_rate": 1.9299908284928155e-05,
      "loss": 1.3941,
      "step": 10500
    },
    {
      "epoch": 1.0700091715071844,
      "eval_loss": 1.2477823495864868,
      "eval_runtime": 199.3792,
      "eval_samples_per_second": 17.374,
      "eval_steps_per_second": 8.687,
      "step": 10500
    },
    {
      "epoch": 1.080199735045348,
      "grad_norm": 2.348341941833496,
      "learning_rate": 1.919800264954652e-05,
      "loss": 1.4696,
      "step": 10600
    },
    {
      "epoch": 1.0903902985835117,
      "grad_norm": 2.965822458267212,
      "learning_rate": 1.9096097014164885e-05,
      "loss": 1.4976,
      "step": 10700
    },
    {
      "epoch": 1.1005808621216753,
      "grad_norm": 2.5905113220214844,
      "learning_rate": 1.8994191378783248e-05,
      "loss": 1.4747,
      "step": 10800
    },
    {
      "epoch": 1.110771425659839,
      "grad_norm": 2.559501886367798,
      "learning_rate": 1.889228574340161e-05,
      "loss": 1.351,
      "step": 10900
    },
    {
      "epoch": 1.1209619891980027,
      "grad_norm": 3.645282506942749,
      "learning_rate": 1.8790380108019975e-05,
      "loss": 1.4971,
      "step": 11000
    },
    {
      "epoch": 1.1209619891980027,
      "eval_loss": 1.2300184965133667,
      "eval_runtime": 200.1336,
      "eval_samples_per_second": 17.308,
      "eval_steps_per_second": 8.654,
      "step": 11000
    },
    {
      "epoch": 1.1311525527361663,
      "grad_norm": 2.910991668701172,
      "learning_rate": 1.8688474472638335e-05,
      "loss": 1.4426,
      "step": 11100
    },
    {
      "epoch": 1.14134311627433,
      "grad_norm": 3.076895236968994,
      "learning_rate": 1.85865688372567e-05,
      "loss": 1.3961,
      "step": 11200
    },
    {
      "epoch": 1.1515336798124935,
      "grad_norm": 4.5148701667785645,
      "learning_rate": 1.8484663201875065e-05,
      "loss": 1.4453,
      "step": 11300
    },
    {
      "epoch": 1.1617242433506574,
      "grad_norm": 5.065725326538086,
      "learning_rate": 1.8382757566493428e-05,
      "loss": 1.4244,
      "step": 11400
    },
    {
      "epoch": 1.171914806888821,
      "grad_norm": 6.902016639709473,
      "learning_rate": 1.828085193111179e-05,
      "loss": 1.398,
      "step": 11500
    },
    {
      "epoch": 1.171914806888821,
      "eval_loss": 1.2245891094207764,
      "eval_runtime": 199.7772,
      "eval_samples_per_second": 17.339,
      "eval_steps_per_second": 8.67,
      "step": 11500
    },
    {
      "epoch": 1.1821053704269846,
      "grad_norm": 3.3813869953155518,
      "learning_rate": 1.8178946295730155e-05,
      "loss": 1.4817,
      "step": 11600
    },
    {
      "epoch": 1.1922959339651482,
      "grad_norm": 3.3772315979003906,
      "learning_rate": 1.8077040660348515e-05,
      "loss": 1.4924,
      "step": 11700
    },
    {
      "epoch": 1.2024864975033118,
      "grad_norm": 4.236727237701416,
      "learning_rate": 1.797513502496688e-05,
      "loss": 1.422,
      "step": 11800
    },
    {
      "epoch": 1.2126770610414757,
      "grad_norm": 2.5937893390655518,
      "learning_rate": 1.7873229389585245e-05,
      "loss": 1.4047,
      "step": 11900
    },
    {
      "epoch": 1.2228676245796393,
      "grad_norm": 3.28621244430542,
      "learning_rate": 1.7771323754203608e-05,
      "loss": 1.3691,
      "step": 12000
    },
    {
      "epoch": 1.2228676245796393,
      "eval_loss": 1.2336848974227905,
      "eval_runtime": 200.3037,
      "eval_samples_per_second": 17.294,
      "eval_steps_per_second": 8.647,
      "step": 12000
    },
    {
      "epoch": 1.2330581881178029,
      "grad_norm": 2.553321361541748,
      "learning_rate": 1.766941811882197e-05,
      "loss": 1.4149,
      "step": 12100
    },
    {
      "epoch": 1.2432487516559665,
      "grad_norm": 10.027904510498047,
      "learning_rate": 1.7567512483440335e-05,
      "loss": 1.4294,
      "step": 12200
    },
    {
      "epoch": 1.25343931519413,
      "grad_norm": 2.570755958557129,
      "learning_rate": 1.7465606848058698e-05,
      "loss": 1.5027,
      "step": 12300
    },
    {
      "epoch": 1.263629878732294,
      "grad_norm": 3.278454303741455,
      "learning_rate": 1.736370121267706e-05,
      "loss": 1.458,
      "step": 12400
    },
    {
      "epoch": 1.2738204422704575,
      "grad_norm": 3.0171589851379395,
      "learning_rate": 1.7261795577295425e-05,
      "loss": 1.4071,
      "step": 12500
    },
    {
      "epoch": 1.2738204422704575,
      "eval_loss": 1.2209100723266602,
      "eval_runtime": 200.9358,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 8.62,
      "step": 12500
    },
    {
      "epoch": 1.2840110058086212,
      "grad_norm": 4.5730881690979,
      "learning_rate": 1.7159889941913788e-05,
      "loss": 1.5265,
      "step": 12600
    },
    {
      "epoch": 1.294201569346785,
      "grad_norm": 3.4026074409484863,
      "learning_rate": 1.705798430653215e-05,
      "loss": 1.4617,
      "step": 12700
    },
    {
      "epoch": 1.3043921328849486,
      "grad_norm": 2.3560714721679688,
      "learning_rate": 1.6956078671150515e-05,
      "loss": 1.4504,
      "step": 12800
    },
    {
      "epoch": 1.3145826964231122,
      "grad_norm": 2.3456461429595947,
      "learning_rate": 1.6854173035768878e-05,
      "loss": 1.4832,
      "step": 12900
    },
    {
      "epoch": 1.3247732599612758,
      "grad_norm": 3.073012113571167,
      "learning_rate": 1.6752267400387245e-05,
      "loss": 1.3938,
      "step": 13000
    },
    {
      "epoch": 1.3247732599612758,
      "eval_loss": 1.2270833253860474,
      "eval_runtime": 201.6679,
      "eval_samples_per_second": 17.177,
      "eval_steps_per_second": 8.588,
      "step": 13000
    },
    {
      "epoch": 1.3349638234994394,
      "grad_norm": 5.477739334106445,
      "learning_rate": 1.6650361765005605e-05,
      "loss": 1.4439,
      "step": 13100
    },
    {
      "epoch": 1.3451543870376033,
      "grad_norm": 2.5260555744171143,
      "learning_rate": 1.6548456129623968e-05,
      "loss": 1.3716,
      "step": 13200
    },
    {
      "epoch": 1.3553449505757669,
      "grad_norm": 2.216676950454712,
      "learning_rate": 1.644655049424233e-05,
      "loss": 1.4039,
      "step": 13300
    },
    {
      "epoch": 1.3655355141139305,
      "grad_norm": 2.7223873138427734,
      "learning_rate": 1.6344644858860695e-05,
      "loss": 1.4595,
      "step": 13400
    },
    {
      "epoch": 1.375726077652094,
      "grad_norm": 2.5102949142456055,
      "learning_rate": 1.6242739223479058e-05,
      "loss": 1.4518,
      "step": 13500
    },
    {
      "epoch": 1.375726077652094,
      "eval_loss": 1.214667797088623,
      "eval_runtime": 201.3437,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 8.602,
      "step": 13500
    },
    {
      "epoch": 1.3859166411902577,
      "grad_norm": 3.070023536682129,
      "learning_rate": 1.6140833588097425e-05,
      "loss": 1.3724,
      "step": 13600
    },
    {
      "epoch": 1.3961072047284215,
      "grad_norm": 5.842353820800781,
      "learning_rate": 1.6038927952715785e-05,
      "loss": 1.4751,
      "step": 13700
    },
    {
      "epoch": 1.4062977682665851,
      "grad_norm": 2.719259023666382,
      "learning_rate": 1.5937022317334148e-05,
      "loss": 1.4546,
      "step": 13800
    },
    {
      "epoch": 1.4164883318047488,
      "grad_norm": 2.194978952407837,
      "learning_rate": 1.583511668195251e-05,
      "loss": 1.4822,
      "step": 13900
    },
    {
      "epoch": 1.4266788953429126,
      "grad_norm": 2.8972208499908447,
      "learning_rate": 1.5733211046570875e-05,
      "loss": 1.5258,
      "step": 14000
    },
    {
      "epoch": 1.4266788953429126,
      "eval_loss": 1.2064175605773926,
      "eval_runtime": 200.7919,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 8.626,
      "step": 14000
    },
    {
      "epoch": 1.4368694588810762,
      "grad_norm": 4.2488555908203125,
      "learning_rate": 1.5631305411189238e-05,
      "loss": 1.4678,
      "step": 14100
    },
    {
      "epoch": 1.4470600224192398,
      "grad_norm": 2.288648843765259,
      "learning_rate": 1.5529399775807605e-05,
      "loss": 1.4407,
      "step": 14200
    },
    {
      "epoch": 1.4572505859574034,
      "grad_norm": 2.587615728378296,
      "learning_rate": 1.5427494140425968e-05,
      "loss": 1.4694,
      "step": 14300
    },
    {
      "epoch": 1.467441149495567,
      "grad_norm": 2.5686097145080566,
      "learning_rate": 1.5325588505044328e-05,
      "loss": 1.4636,
      "step": 14400
    },
    {
      "epoch": 1.4776317130337309,
      "grad_norm": 2.998544454574585,
      "learning_rate": 1.5223682869662692e-05,
      "loss": 1.3913,
      "step": 14500
    },
    {
      "epoch": 1.4776317130337309,
      "eval_loss": 1.2060518264770508,
      "eval_runtime": 201.5719,
      "eval_samples_per_second": 17.185,
      "eval_steps_per_second": 8.592,
      "step": 14500
    },
    {
      "epoch": 1.4878222765718945,
      "grad_norm": 2.4548134803771973,
      "learning_rate": 1.5121777234281055e-05,
      "loss": 1.422,
      "step": 14600
    },
    {
      "epoch": 1.498012840110058,
      "grad_norm": 3.3229777812957764,
      "learning_rate": 1.501987159889942e-05,
      "loss": 1.399,
      "step": 14700
    },
    {
      "epoch": 1.5082034036482217,
      "grad_norm": 2.2541661262512207,
      "learning_rate": 1.4917965963517783e-05,
      "loss": 1.442,
      "step": 14800
    },
    {
      "epoch": 1.5183939671863853,
      "grad_norm": 3.640695571899414,
      "learning_rate": 1.4816060328136145e-05,
      "loss": 1.5,
      "step": 14900
    },
    {
      "epoch": 1.5285845307245491,
      "grad_norm": 2.6724917888641357,
      "learning_rate": 1.471415469275451e-05,
      "loss": 1.3577,
      "step": 15000
    },
    {
      "epoch": 1.5285845307245491,
      "eval_loss": 1.2142071723937988,
      "eval_runtime": 201.0199,
      "eval_samples_per_second": 17.232,
      "eval_steps_per_second": 8.616,
      "step": 15000
    },
    {
      "epoch": 1.5387750942627128,
      "grad_norm": 3.545664072036743,
      "learning_rate": 1.4612249057372873e-05,
      "loss": 1.4423,
      "step": 15100
    },
    {
      "epoch": 1.5489656578008764,
      "grad_norm": 104.90357971191406,
      "learning_rate": 1.4510343421991237e-05,
      "loss": 1.5439,
      "step": 15200
    },
    {
      "epoch": 1.5591562213390402,
      "grad_norm": 7.277150630950928,
      "learning_rate": 1.44084377866096e-05,
      "loss": 1.4075,
      "step": 15300
    },
    {
      "epoch": 1.5693467848772036,
      "grad_norm": 3.9275786876678467,
      "learning_rate": 1.4306532151227963e-05,
      "loss": 1.4251,
      "step": 15400
    },
    {
      "epoch": 1.5795373484153674,
      "grad_norm": 4.462745666503906,
      "learning_rate": 1.4204626515846327e-05,
      "loss": 1.4663,
      "step": 15500
    },
    {
      "epoch": 1.5795373484153674,
      "eval_loss": 1.2061939239501953,
      "eval_runtime": 201.6441,
      "eval_samples_per_second": 17.179,
      "eval_steps_per_second": 8.589,
      "step": 15500
    },
    {
      "epoch": 1.589727911953531,
      "grad_norm": 2.8855602741241455,
      "learning_rate": 1.410272088046469e-05,
      "loss": 1.4355,
      "step": 15600
    },
    {
      "epoch": 1.5999184754916946,
      "grad_norm": 3.0141897201538086,
      "learning_rate": 1.4000815245083053e-05,
      "loss": 1.4534,
      "step": 15700
    },
    {
      "epoch": 1.6101090390298585,
      "grad_norm": 3.4975733757019043,
      "learning_rate": 1.3898909609701417e-05,
      "loss": 1.4,
      "step": 15800
    },
    {
      "epoch": 1.6202996025680219,
      "grad_norm": 3.76729679107666,
      "learning_rate": 1.379700397431978e-05,
      "loss": 1.4333,
      "step": 15900
    },
    {
      "epoch": 1.6304901661061857,
      "grad_norm": 3.1804327964782715,
      "learning_rate": 1.3695098338938143e-05,
      "loss": 1.4138,
      "step": 16000
    },
    {
      "epoch": 1.6304901661061857,
      "eval_loss": 1.203220009803772,
      "eval_runtime": 202.1576,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 8.568,
      "step": 16000
    },
    {
      "epoch": 1.6406807296443493,
      "grad_norm": 2.815943956375122,
      "learning_rate": 1.3593192703556507e-05,
      "loss": 1.4696,
      "step": 16100
    },
    {
      "epoch": 1.650871293182513,
      "grad_norm": 3.1883304119110107,
      "learning_rate": 1.3491287068174872e-05,
      "loss": 1.4951,
      "step": 16200
    },
    {
      "epoch": 1.6610618567206767,
      "grad_norm": 2.29194974899292,
      "learning_rate": 1.3389381432793233e-05,
      "loss": 1.4069,
      "step": 16300
    },
    {
      "epoch": 1.6712524202588404,
      "grad_norm": 6.129655361175537,
      "learning_rate": 1.3287475797411597e-05,
      "loss": 1.4288,
      "step": 16400
    },
    {
      "epoch": 1.681442983797004,
      "grad_norm": 3.076737880706787,
      "learning_rate": 1.3185570162029962e-05,
      "loss": 1.4542,
      "step": 16500
    },
    {
      "epoch": 1.681442983797004,
      "eval_loss": 1.2080038785934448,
      "eval_runtime": 202.512,
      "eval_samples_per_second": 17.105,
      "eval_steps_per_second": 8.553,
      "step": 16500
    },
    {
      "epoch": 1.6916335473351678,
      "grad_norm": 3.251619577407837,
      "learning_rate": 1.3083664526648323e-05,
      "loss": 1.4271,
      "step": 16600
    },
    {
      "epoch": 1.7018241108733312,
      "grad_norm": 2.704101085662842,
      "learning_rate": 1.2981758891266687e-05,
      "loss": 1.3849,
      "step": 16700
    },
    {
      "epoch": 1.712014674411495,
      "grad_norm": 3.0535261631011963,
      "learning_rate": 1.2879853255885052e-05,
      "loss": 1.4233,
      "step": 16800
    },
    {
      "epoch": 1.7222052379496586,
      "grad_norm": 3.7566263675689697,
      "learning_rate": 1.2777947620503413e-05,
      "loss": 1.403,
      "step": 16900
    },
    {
      "epoch": 1.7323958014878222,
      "grad_norm": 2.2097835540771484,
      "learning_rate": 1.2676041985121777e-05,
      "loss": 1.4373,
      "step": 17000
    },
    {
      "epoch": 1.7323958014878222,
      "eval_loss": 1.2090322971343994,
      "eval_runtime": 203.6163,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 8.506,
      "step": 17000
    },
    {
      "epoch": 1.742586365025986,
      "grad_norm": 2.8264122009277344,
      "learning_rate": 1.2574136349740142e-05,
      "loss": 1.5439,
      "step": 17100
    },
    {
      "epoch": 1.7527769285641495,
      "grad_norm": 2.693540334701538,
      "learning_rate": 1.2472230714358505e-05,
      "loss": 1.4973,
      "step": 17200
    },
    {
      "epoch": 1.7629674921023133,
      "grad_norm": 4.3233418464660645,
      "learning_rate": 1.2370325078976867e-05,
      "loss": 1.3694,
      "step": 17300
    },
    {
      "epoch": 1.773158055640477,
      "grad_norm": 3.3947861194610596,
      "learning_rate": 1.2268419443595232e-05,
      "loss": 1.3922,
      "step": 17400
    },
    {
      "epoch": 1.7833486191786405,
      "grad_norm": 4.219278812408447,
      "learning_rate": 1.2166513808213595e-05,
      "loss": 1.4296,
      "step": 17500
    },
    {
      "epoch": 1.7833486191786405,
      "eval_loss": 1.1957221031188965,
      "eval_runtime": 203.5161,
      "eval_samples_per_second": 17.021,
      "eval_steps_per_second": 8.51,
      "step": 17500
    },
    {
      "epoch": 1.7935391827168043,
      "grad_norm": 3.216604709625244,
      "learning_rate": 1.2064608172831957e-05,
      "loss": 1.4799,
      "step": 17600
    },
    {
      "epoch": 1.8037297462549677,
      "grad_norm": 11.219060897827148,
      "learning_rate": 1.1962702537450322e-05,
      "loss": 1.4529,
      "step": 17700
    },
    {
      "epoch": 1.8139203097931316,
      "grad_norm": 2.3660342693328857,
      "learning_rate": 1.1860796902068685e-05,
      "loss": 1.3976,
      "step": 17800
    },
    {
      "epoch": 1.8241108733312952,
      "grad_norm": 3.2880263328552246,
      "learning_rate": 1.1758891266687047e-05,
      "loss": 1.4745,
      "step": 17900
    },
    {
      "epoch": 1.8343014368694588,
      "grad_norm": 3.1469075679779053,
      "learning_rate": 1.1656985631305412e-05,
      "loss": 1.3293,
      "step": 18000
    },
    {
      "epoch": 1.8343014368694588,
      "eval_loss": 1.1979666948318481,
      "eval_runtime": 205.0073,
      "eval_samples_per_second": 16.897,
      "eval_steps_per_second": 8.448,
      "step": 18000
    },
    {
      "epoch": 1.8444920004076226,
      "grad_norm": 3.134064197540283,
      "learning_rate": 1.1555079995923775e-05,
      "loss": 1.519,
      "step": 18100
    },
    {
      "epoch": 1.8546825639457862,
      "grad_norm": 2.773073434829712,
      "learning_rate": 1.1453174360542138e-05,
      "loss": 1.4029,
      "step": 18200
    },
    {
      "epoch": 1.8648731274839498,
      "grad_norm": 2.954782247543335,
      "learning_rate": 1.1351268725160502e-05,
      "loss": 1.4303,
      "step": 18300
    },
    {
      "epoch": 1.8750636910221137,
      "grad_norm": 2.470346212387085,
      "learning_rate": 1.1249363089778865e-05,
      "loss": 1.4192,
      "step": 18400
    },
    {
      "epoch": 1.885254254560277,
      "grad_norm": 2.40605092048645,
      "learning_rate": 1.1147457454397228e-05,
      "loss": 1.4912,
      "step": 18500
    },
    {
      "epoch": 1.885254254560277,
      "eval_loss": 1.1852672100067139,
      "eval_runtime": 203.7267,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 8.502,
      "step": 18500
    }
  ],
  "logging_steps": 100,
  "max_steps": 29439,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1076149663622758e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
