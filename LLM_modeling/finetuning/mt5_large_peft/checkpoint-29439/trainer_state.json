{
  "best_metric": 1.1852672100067139,
  "best_model_checkpoint": "./mt5_large_peft\\checkpoint-18500",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 29439,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010190563538163661,
      "grad_norm": 27453.126953125,
      "learning_rate": 2.9898094364618364e-05,
      "loss": 28.2202,
      "step": 100
    },
    {
      "epoch": 0.020381127076327322,
      "grad_norm": 6308.0859375,
      "learning_rate": 2.9796188729236727e-05,
      "loss": 27.3786,
      "step": 200
    },
    {
      "epoch": 0.03057169061449098,
      "grad_norm": 2764.48779296875,
      "learning_rate": 2.969428309385509e-05,
      "loss": 24.3512,
      "step": 300
    },
    {
      "epoch": 0.040762254152654644,
      "grad_norm": 5947.34814453125,
      "learning_rate": 2.9592377458473454e-05,
      "loss": 20.3978,
      "step": 400
    },
    {
      "epoch": 0.0509528176908183,
      "grad_norm": 3450.567626953125,
      "learning_rate": 2.9490471823091817e-05,
      "loss": 19.3209,
      "step": 500
    },
    {
      "epoch": 0.0509528176908183,
      "eval_loss": 13.17918872833252,
      "eval_runtime": 164.9778,
      "eval_samples_per_second": 20.997,
      "eval_steps_per_second": 10.498,
      "step": 500
    },
    {
      "epoch": 0.06114338122898196,
      "grad_norm": 281.2143249511719,
      "learning_rate": 2.938856618771018e-05,
      "loss": 15.881,
      "step": 600
    },
    {
      "epoch": 0.07133394476714562,
      "grad_norm": 4795.501953125,
      "learning_rate": 2.9286660552328544e-05,
      "loss": 14.4896,
      "step": 700
    },
    {
      "epoch": 0.08152450830530929,
      "grad_norm": 3667.901123046875,
      "learning_rate": 2.9184754916946907e-05,
      "loss": 12.2237,
      "step": 800
    },
    {
      "epoch": 0.09171507184347294,
      "grad_norm": 202.11444091796875,
      "learning_rate": 2.908284928156527e-05,
      "loss": 9.8659,
      "step": 900
    },
    {
      "epoch": 0.1019056353816366,
      "grad_norm": 72.45142364501953,
      "learning_rate": 2.8980943646183638e-05,
      "loss": 8.5164,
      "step": 1000
    },
    {
      "epoch": 0.1019056353816366,
      "eval_loss": 5.212243556976318,
      "eval_runtime": 164.7978,
      "eval_samples_per_second": 21.02,
      "eval_steps_per_second": 10.51,
      "step": 1000
    },
    {
      "epoch": 0.11209619891980027,
      "grad_norm": 15.142948150634766,
      "learning_rate": 2.8879038010801997e-05,
      "loss": 6.0471,
      "step": 1100
    },
    {
      "epoch": 0.12228676245796392,
      "grad_norm": 3.3956282138824463,
      "learning_rate": 2.877713237542036e-05,
      "loss": 3.2172,
      "step": 1200
    },
    {
      "epoch": 0.13247732599612758,
      "grad_norm": 2.6316514015197754,
      "learning_rate": 2.8675226740038724e-05,
      "loss": 2.5159,
      "step": 1300
    },
    {
      "epoch": 0.14266788953429124,
      "grad_norm": 3.639423370361328,
      "learning_rate": 2.8573321104657087e-05,
      "loss": 2.2805,
      "step": 1400
    },
    {
      "epoch": 0.1528584530724549,
      "grad_norm": 3.6864843368530273,
      "learning_rate": 2.847141546927545e-05,
      "loss": 2.04,
      "step": 1500
    },
    {
      "epoch": 0.1528584530724549,
      "eval_loss": 1.5683362483978271,
      "eval_runtime": 175.8535,
      "eval_samples_per_second": 19.698,
      "eval_steps_per_second": 9.849,
      "step": 1500
    },
    {
      "epoch": 0.16304901661061857,
      "grad_norm": 8.59614086151123,
      "learning_rate": 2.8369509833893818e-05,
      "loss": 2.1247,
      "step": 1600
    },
    {
      "epoch": 0.17323958014878224,
      "grad_norm": 2.726902961730957,
      "learning_rate": 2.8267604198512178e-05,
      "loss": 1.909,
      "step": 1700
    },
    {
      "epoch": 0.18343014368694588,
      "grad_norm": 5.7329864501953125,
      "learning_rate": 2.816569856313054e-05,
      "loss": 1.8978,
      "step": 1800
    },
    {
      "epoch": 0.19362070722510955,
      "grad_norm": 2.2479844093322754,
      "learning_rate": 2.8063792927748904e-05,
      "loss": 1.8325,
      "step": 1900
    },
    {
      "epoch": 0.2038112707632732,
      "grad_norm": 2.9731550216674805,
      "learning_rate": 2.7961887292367268e-05,
      "loss": 1.8252,
      "step": 2000
    },
    {
      "epoch": 0.2038112707632732,
      "eval_loss": 1.4640119075775146,
      "eval_runtime": 182.7855,
      "eval_samples_per_second": 18.951,
      "eval_steps_per_second": 9.476,
      "step": 2000
    },
    {
      "epoch": 0.21400183430143688,
      "grad_norm": 5.605309009552002,
      "learning_rate": 2.785998165698563e-05,
      "loss": 1.8403,
      "step": 2100
    },
    {
      "epoch": 0.22419239783960054,
      "grad_norm": 2.940595865249634,
      "learning_rate": 2.7758076021603998e-05,
      "loss": 1.7635,
      "step": 2200
    },
    {
      "epoch": 0.23438296137776418,
      "grad_norm": 2.7001793384552,
      "learning_rate": 2.765617038622236e-05,
      "loss": 1.8404,
      "step": 2300
    },
    {
      "epoch": 0.24457352491592785,
      "grad_norm": 2.429716110229492,
      "learning_rate": 2.755426475084072e-05,
      "loss": 1.7498,
      "step": 2400
    },
    {
      "epoch": 0.2547640884540915,
      "grad_norm": 3.242645740509033,
      "learning_rate": 2.7452359115459084e-05,
      "loss": 1.8226,
      "step": 2500
    },
    {
      "epoch": 0.2547640884540915,
      "eval_loss": 1.4022103548049927,
      "eval_runtime": 188.2106,
      "eval_samples_per_second": 18.405,
      "eval_steps_per_second": 9.202,
      "step": 2500
    },
    {
      "epoch": 0.26495465199225515,
      "grad_norm": 3.6384782791137695,
      "learning_rate": 2.7350453480077448e-05,
      "loss": 1.7999,
      "step": 2600
    },
    {
      "epoch": 0.2751452155304188,
      "grad_norm": 2.0548856258392334,
      "learning_rate": 2.724854784469581e-05,
      "loss": 1.8131,
      "step": 2700
    },
    {
      "epoch": 0.2853357790685825,
      "grad_norm": 3.25698184967041,
      "learning_rate": 2.7146642209314178e-05,
      "loss": 1.6744,
      "step": 2800
    },
    {
      "epoch": 0.29552634260674615,
      "grad_norm": 3.2758820056915283,
      "learning_rate": 2.704473657393254e-05,
      "loss": 1.7561,
      "step": 2900
    },
    {
      "epoch": 0.3057169061449098,
      "grad_norm": 2.1602401733398438,
      "learning_rate": 2.6942830938550904e-05,
      "loss": 1.6305,
      "step": 3000
    },
    {
      "epoch": 0.3057169061449098,
      "eval_loss": 1.38109290599823,
      "eval_runtime": 194.9073,
      "eval_samples_per_second": 17.773,
      "eval_steps_per_second": 8.886,
      "step": 3000
    },
    {
      "epoch": 0.3159074696830735,
      "grad_norm": 4.970451354980469,
      "learning_rate": 2.6840925303169264e-05,
      "loss": 1.6063,
      "step": 3100
    },
    {
      "epoch": 0.32609803322123715,
      "grad_norm": 3.5661942958831787,
      "learning_rate": 2.6739019667787628e-05,
      "loss": 1.7028,
      "step": 3200
    },
    {
      "epoch": 0.3362885967594008,
      "grad_norm": 3.0770022869110107,
      "learning_rate": 2.663711403240599e-05,
      "loss": 1.6922,
      "step": 3300
    },
    {
      "epoch": 0.3464791602975645,
      "grad_norm": 9.248029708862305,
      "learning_rate": 2.6535208397024358e-05,
      "loss": 1.6022,
      "step": 3400
    },
    {
      "epoch": 0.3566697238357281,
      "grad_norm": 4.056350231170654,
      "learning_rate": 2.643330276164272e-05,
      "loss": 1.7081,
      "step": 3500
    },
    {
      "epoch": 0.3566697238357281,
      "eval_loss": 1.358703851699829,
      "eval_runtime": 197.1859,
      "eval_samples_per_second": 17.567,
      "eval_steps_per_second": 8.784,
      "step": 3500
    },
    {
      "epoch": 0.36686028737389176,
      "grad_norm": 4.463601112365723,
      "learning_rate": 2.6331397126261084e-05,
      "loss": 1.6415,
      "step": 3600
    },
    {
      "epoch": 0.3770508509120554,
      "grad_norm": 1.8606330156326294,
      "learning_rate": 2.6229491490879444e-05,
      "loss": 1.6281,
      "step": 3700
    },
    {
      "epoch": 0.3872414144502191,
      "grad_norm": 3.250900983810425,
      "learning_rate": 2.6127585855497808e-05,
      "loss": 1.6821,
      "step": 3800
    },
    {
      "epoch": 0.39743197798838276,
      "grad_norm": 3.322420597076416,
      "learning_rate": 2.602568022011617e-05,
      "loss": 1.6299,
      "step": 3900
    },
    {
      "epoch": 0.4076225415265464,
      "grad_norm": 2.563308000564575,
      "learning_rate": 2.5923774584734538e-05,
      "loss": 1.684,
      "step": 4000
    },
    {
      "epoch": 0.4076225415265464,
      "eval_loss": 1.3363786935806274,
      "eval_runtime": 196.3734,
      "eval_samples_per_second": 17.64,
      "eval_steps_per_second": 8.82,
      "step": 4000
    },
    {
      "epoch": 0.4178131050647101,
      "grad_norm": 2.463371515274048,
      "learning_rate": 2.58218689493529e-05,
      "loss": 1.6033,
      "step": 4100
    },
    {
      "epoch": 0.42800366860287375,
      "grad_norm": 29.73354148864746,
      "learning_rate": 2.5719963313971264e-05,
      "loss": 1.633,
      "step": 4200
    },
    {
      "epoch": 0.4381942321410374,
      "grad_norm": 3.0809860229492188,
      "learning_rate": 2.5618057678589628e-05,
      "loss": 1.6004,
      "step": 4300
    },
    {
      "epoch": 0.4483847956792011,
      "grad_norm": 2.6930699348449707,
      "learning_rate": 2.5516152043207988e-05,
      "loss": 1.6562,
      "step": 4400
    },
    {
      "epoch": 0.4585753592173647,
      "grad_norm": 2.620406150817871,
      "learning_rate": 2.541424640782635e-05,
      "loss": 1.5907,
      "step": 4500
    },
    {
      "epoch": 0.4585753592173647,
      "eval_loss": 1.3071873188018799,
      "eval_runtime": 196.574,
      "eval_samples_per_second": 17.622,
      "eval_steps_per_second": 8.811,
      "step": 4500
    },
    {
      "epoch": 0.46876592275552836,
      "grad_norm": 2.7053122520446777,
      "learning_rate": 2.5312340772444718e-05,
      "loss": 1.586,
      "step": 4600
    },
    {
      "epoch": 0.47895648629369203,
      "grad_norm": 2.8677291870117188,
      "learning_rate": 2.521043513706308e-05,
      "loss": 1.5709,
      "step": 4700
    },
    {
      "epoch": 0.4891470498318557,
      "grad_norm": 2.8104186058044434,
      "learning_rate": 2.5108529501681444e-05,
      "loss": 1.5965,
      "step": 4800
    },
    {
      "epoch": 0.49933761337001936,
      "grad_norm": 2.296156167984009,
      "learning_rate": 2.5006623866299808e-05,
      "loss": 1.5657,
      "step": 4900
    },
    {
      "epoch": 0.509528176908183,
      "grad_norm": 3.4835751056671143,
      "learning_rate": 2.490471823091817e-05,
      "loss": 1.6203,
      "step": 5000
    },
    {
      "epoch": 0.509528176908183,
      "eval_loss": 1.304913878440857,
      "eval_runtime": 197.8511,
      "eval_samples_per_second": 17.508,
      "eval_steps_per_second": 8.754,
      "step": 5000
    },
    {
      "epoch": 0.5197187404463467,
      "grad_norm": 1.97618567943573,
      "learning_rate": 2.480281259553653e-05,
      "loss": 1.556,
      "step": 5100
    },
    {
      "epoch": 0.5299093039845103,
      "grad_norm": 2.2320876121520996,
      "learning_rate": 2.4700906960154898e-05,
      "loss": 1.5569,
      "step": 5200
    },
    {
      "epoch": 0.540099867522674,
      "grad_norm": 2.9004650115966797,
      "learning_rate": 2.459900132477326e-05,
      "loss": 1.6221,
      "step": 5300
    },
    {
      "epoch": 0.5502904310608376,
      "grad_norm": 4.157751083374023,
      "learning_rate": 2.4497095689391624e-05,
      "loss": 1.5728,
      "step": 5400
    },
    {
      "epoch": 0.5604809945990014,
      "grad_norm": 7.6900200843811035,
      "learning_rate": 2.4395190054009988e-05,
      "loss": 1.6044,
      "step": 5500
    },
    {
      "epoch": 0.5604809945990014,
      "eval_loss": 1.2923901081085205,
      "eval_runtime": 195.7085,
      "eval_samples_per_second": 17.7,
      "eval_steps_per_second": 8.85,
      "step": 5500
    },
    {
      "epoch": 0.570671558137165,
      "grad_norm": 2.8713998794555664,
      "learning_rate": 2.429328441862835e-05,
      "loss": 1.5075,
      "step": 5600
    },
    {
      "epoch": 0.5808621216753287,
      "grad_norm": 2.7488250732421875,
      "learning_rate": 2.419137878324671e-05,
      "loss": 1.5439,
      "step": 5700
    },
    {
      "epoch": 0.5910526852134923,
      "grad_norm": 2.2639999389648438,
      "learning_rate": 2.4089473147865078e-05,
      "loss": 1.558,
      "step": 5800
    },
    {
      "epoch": 0.6012432487516559,
      "grad_norm": 37.6833610534668,
      "learning_rate": 2.398756751248344e-05,
      "loss": 1.5405,
      "step": 5900
    },
    {
      "epoch": 0.6114338122898196,
      "grad_norm": 3.5379674434661865,
      "learning_rate": 2.3885661877101804e-05,
      "loss": 1.668,
      "step": 6000
    },
    {
      "epoch": 0.6114338122898196,
      "eval_loss": 1.2729147672653198,
      "eval_runtime": 195.9285,
      "eval_samples_per_second": 17.68,
      "eval_steps_per_second": 8.84,
      "step": 6000
    },
    {
      "epoch": 0.6216243758279832,
      "grad_norm": 2.1992745399475098,
      "learning_rate": 2.3783756241720168e-05,
      "loss": 1.5117,
      "step": 6100
    },
    {
      "epoch": 0.631814939366147,
      "grad_norm": 3.0455079078674316,
      "learning_rate": 2.368185060633853e-05,
      "loss": 1.5144,
      "step": 6200
    },
    {
      "epoch": 0.6420055029043106,
      "grad_norm": 9.293886184692383,
      "learning_rate": 2.3579944970956894e-05,
      "loss": 1.577,
      "step": 6300
    },
    {
      "epoch": 0.6521960664424743,
      "grad_norm": 4.486127853393555,
      "learning_rate": 2.3478039335575258e-05,
      "loss": 1.52,
      "step": 6400
    },
    {
      "epoch": 0.6623866299806379,
      "grad_norm": 2.36458683013916,
      "learning_rate": 2.337613370019362e-05,
      "loss": 1.4031,
      "step": 6500
    },
    {
      "epoch": 0.6623866299806379,
      "eval_loss": 1.2933416366577148,
      "eval_runtime": 197.7927,
      "eval_samples_per_second": 17.513,
      "eval_steps_per_second": 8.757,
      "step": 6500
    },
    {
      "epoch": 0.6725771935188016,
      "grad_norm": 1.905340313911438,
      "learning_rate": 2.3274228064811984e-05,
      "loss": 1.6044,
      "step": 6600
    },
    {
      "epoch": 0.6827677570569652,
      "grad_norm": 2.296320676803589,
      "learning_rate": 2.3172322429430348e-05,
      "loss": 1.4941,
      "step": 6700
    },
    {
      "epoch": 0.692958320595129,
      "grad_norm": 3.882049560546875,
      "learning_rate": 2.307041679404871e-05,
      "loss": 1.6335,
      "step": 6800
    },
    {
      "epoch": 0.7031488841332926,
      "grad_norm": 2.8761281967163086,
      "learning_rate": 2.2968511158667074e-05,
      "loss": 1.6041,
      "step": 6900
    },
    {
      "epoch": 0.7133394476714562,
      "grad_norm": 2.7323718070983887,
      "learning_rate": 2.286660552328544e-05,
      "loss": 1.5593,
      "step": 7000
    },
    {
      "epoch": 0.7133394476714562,
      "eval_loss": 1.2611290216445923,
      "eval_runtime": 196.812,
      "eval_samples_per_second": 17.601,
      "eval_steps_per_second": 8.8,
      "step": 7000
    },
    {
      "epoch": 0.7235300112096199,
      "grad_norm": 4.449601173400879,
      "learning_rate": 2.27646998879038e-05,
      "loss": 1.5278,
      "step": 7100
    },
    {
      "epoch": 0.7337205747477835,
      "grad_norm": 2.6258163452148438,
      "learning_rate": 2.2662794252522164e-05,
      "loss": 1.611,
      "step": 7200
    },
    {
      "epoch": 0.7439111382859472,
      "grad_norm": 2.62459397315979,
      "learning_rate": 2.2560888617140528e-05,
      "loss": 1.5234,
      "step": 7300
    },
    {
      "epoch": 0.7541017018241108,
      "grad_norm": 4.098433494567871,
      "learning_rate": 2.245898298175889e-05,
      "loss": 1.5637,
      "step": 7400
    },
    {
      "epoch": 0.7642922653622746,
      "grad_norm": 2.9748430252075195,
      "learning_rate": 2.2357077346377254e-05,
      "loss": 1.5189,
      "step": 7500
    },
    {
      "epoch": 0.7642922653622746,
      "eval_loss": 1.2658799886703491,
      "eval_runtime": 196.8755,
      "eval_samples_per_second": 17.595,
      "eval_steps_per_second": 8.797,
      "step": 7500
    },
    {
      "epoch": 0.7744828289004382,
      "grad_norm": 2.6296234130859375,
      "learning_rate": 2.225517171099562e-05,
      "loss": 1.5699,
      "step": 7600
    },
    {
      "epoch": 0.7846733924386019,
      "grad_norm": 10.41512680053711,
      "learning_rate": 2.215326607561398e-05,
      "loss": 1.4323,
      "step": 7700
    },
    {
      "epoch": 0.7948639559767655,
      "grad_norm": 25.46101188659668,
      "learning_rate": 2.2051360440232344e-05,
      "loss": 1.4018,
      "step": 7800
    },
    {
      "epoch": 0.8050545195149291,
      "grad_norm": 2.717301607131958,
      "learning_rate": 2.1949454804850708e-05,
      "loss": 1.5025,
      "step": 7900
    },
    {
      "epoch": 0.8152450830530928,
      "grad_norm": 3.346304178237915,
      "learning_rate": 2.184754916946907e-05,
      "loss": 1.4063,
      "step": 8000
    },
    {
      "epoch": 0.8152450830530928,
      "eval_loss": 1.2586015462875366,
      "eval_runtime": 197.502,
      "eval_samples_per_second": 17.539,
      "eval_steps_per_second": 8.77,
      "step": 8000
    },
    {
      "epoch": 0.8254356465912565,
      "grad_norm": 2.2443106174468994,
      "learning_rate": 2.1745643534087435e-05,
      "loss": 1.5544,
      "step": 8100
    },
    {
      "epoch": 0.8356262101294202,
      "grad_norm": 4.1299591064453125,
      "learning_rate": 2.16437378987058e-05,
      "loss": 1.4979,
      "step": 8200
    },
    {
      "epoch": 0.8458167736675838,
      "grad_norm": 3.884678840637207,
      "learning_rate": 2.1541832263324165e-05,
      "loss": 1.4819,
      "step": 8300
    },
    {
      "epoch": 0.8560073372057475,
      "grad_norm": 4.754950523376465,
      "learning_rate": 2.1439926627942525e-05,
      "loss": 1.4972,
      "step": 8400
    },
    {
      "epoch": 0.8661979007439111,
      "grad_norm": 2.6721060276031494,
      "learning_rate": 2.1338020992560888e-05,
      "loss": 1.5716,
      "step": 8500
    },
    {
      "epoch": 0.8661979007439111,
      "eval_loss": 1.2622021436691284,
      "eval_runtime": 197.0185,
      "eval_samples_per_second": 17.582,
      "eval_steps_per_second": 8.791,
      "step": 8500
    },
    {
      "epoch": 0.8763884642820748,
      "grad_norm": 3.109265089035034,
      "learning_rate": 2.123611535717925e-05,
      "loss": 1.4233,
      "step": 8600
    },
    {
      "epoch": 0.8865790278202385,
      "grad_norm": 2.4745090007781982,
      "learning_rate": 2.1134209721797615e-05,
      "loss": 1.497,
      "step": 8700
    },
    {
      "epoch": 0.8967695913584022,
      "grad_norm": 3.1822710037231445,
      "learning_rate": 2.103230408641598e-05,
      "loss": 1.4493,
      "step": 8800
    },
    {
      "epoch": 0.9069601548965658,
      "grad_norm": 2.3245742321014404,
      "learning_rate": 2.0930398451034345e-05,
      "loss": 1.4934,
      "step": 8900
    },
    {
      "epoch": 0.9171507184347294,
      "grad_norm": 5.645829200744629,
      "learning_rate": 2.0828492815652708e-05,
      "loss": 1.5157,
      "step": 9000
    },
    {
      "epoch": 0.9171507184347294,
      "eval_loss": 1.2326971292495728,
      "eval_runtime": 198.5304,
      "eval_samples_per_second": 17.448,
      "eval_steps_per_second": 8.724,
      "step": 9000
    },
    {
      "epoch": 0.9273412819728931,
      "grad_norm": 3.431851387023926,
      "learning_rate": 2.0726587180271068e-05,
      "loss": 1.4571,
      "step": 9100
    },
    {
      "epoch": 0.9375318455110567,
      "grad_norm": 3.475478410720825,
      "learning_rate": 2.062468154488943e-05,
      "loss": 1.537,
      "step": 9200
    },
    {
      "epoch": 0.9477224090492204,
      "grad_norm": 3.1932883262634277,
      "learning_rate": 2.0522775909507795e-05,
      "loss": 1.4792,
      "step": 9300
    },
    {
      "epoch": 0.9579129725873841,
      "grad_norm": 3.1770684719085693,
      "learning_rate": 2.042087027412616e-05,
      "loss": 1.4273,
      "step": 9400
    },
    {
      "epoch": 0.9681035361255478,
      "grad_norm": 3.178551197052002,
      "learning_rate": 2.0318964638744525e-05,
      "loss": 1.4054,
      "step": 9500
    },
    {
      "epoch": 0.9681035361255478,
      "eval_loss": 1.2414758205413818,
      "eval_runtime": 197.9385,
      "eval_samples_per_second": 17.5,
      "eval_steps_per_second": 8.75,
      "step": 9500
    },
    {
      "epoch": 0.9782940996637114,
      "grad_norm": 2.45326828956604,
      "learning_rate": 2.0217059003362888e-05,
      "loss": 1.505,
      "step": 9600
    },
    {
      "epoch": 0.9884846632018751,
      "grad_norm": 2.089677572250366,
      "learning_rate": 2.0115153367981248e-05,
      "loss": 1.478,
      "step": 9700
    },
    {
      "epoch": 0.9986752267400387,
      "grad_norm": 4.328531742095947,
      "learning_rate": 2.001324773259961e-05,
      "loss": 1.4937,
      "step": 9800
    },
    {
      "epoch": 1.0088657902782023,
      "grad_norm": 2.9406490325927734,
      "learning_rate": 1.9911342097217975e-05,
      "loss": 1.526,
      "step": 9900
    },
    {
      "epoch": 1.019056353816366,
      "grad_norm": 2.572849988937378,
      "learning_rate": 1.980943646183634e-05,
      "loss": 1.4422,
      "step": 10000
    },
    {
      "epoch": 1.019056353816366,
      "eval_loss": 1.2440717220306396,
      "eval_runtime": 199.4125,
      "eval_samples_per_second": 17.371,
      "eval_steps_per_second": 8.686,
      "step": 10000
    },
    {
      "epoch": 1.0292469173545298,
      "grad_norm": 2.2916643619537354,
      "learning_rate": 1.9707530826454705e-05,
      "loss": 1.4889,
      "step": 10100
    },
    {
      "epoch": 1.0394374808926934,
      "grad_norm": 3.943711757659912,
      "learning_rate": 1.9605625191073068e-05,
      "loss": 1.5181,
      "step": 10200
    },
    {
      "epoch": 1.049628044430857,
      "grad_norm": 2.0316896438598633,
      "learning_rate": 1.950371955569143e-05,
      "loss": 1.4489,
      "step": 10300
    },
    {
      "epoch": 1.0598186079690206,
      "grad_norm": 2.2818784713745117,
      "learning_rate": 1.940181392030979e-05,
      "loss": 1.4468,
      "step": 10400
    },
    {
      "epoch": 1.0700091715071844,
      "grad_norm": 4.600247383117676,
      "learning_rate": 1.9299908284928155e-05,
      "loss": 1.3941,
      "step": 10500
    },
    {
      "epoch": 1.0700091715071844,
      "eval_loss": 1.2477823495864868,
      "eval_runtime": 199.3792,
      "eval_samples_per_second": 17.374,
      "eval_steps_per_second": 8.687,
      "step": 10500
    },
    {
      "epoch": 1.080199735045348,
      "grad_norm": 2.348341941833496,
      "learning_rate": 1.919800264954652e-05,
      "loss": 1.4696,
      "step": 10600
    },
    {
      "epoch": 1.0903902985835117,
      "grad_norm": 2.965822458267212,
      "learning_rate": 1.9096097014164885e-05,
      "loss": 1.4976,
      "step": 10700
    },
    {
      "epoch": 1.1005808621216753,
      "grad_norm": 2.5905113220214844,
      "learning_rate": 1.8994191378783248e-05,
      "loss": 1.4747,
      "step": 10800
    },
    {
      "epoch": 1.110771425659839,
      "grad_norm": 2.559501886367798,
      "learning_rate": 1.889228574340161e-05,
      "loss": 1.351,
      "step": 10900
    },
    {
      "epoch": 1.1209619891980027,
      "grad_norm": 3.645282506942749,
      "learning_rate": 1.8790380108019975e-05,
      "loss": 1.4971,
      "step": 11000
    },
    {
      "epoch": 1.1209619891980027,
      "eval_loss": 1.2300184965133667,
      "eval_runtime": 200.1336,
      "eval_samples_per_second": 17.308,
      "eval_steps_per_second": 8.654,
      "step": 11000
    },
    {
      "epoch": 1.1311525527361663,
      "grad_norm": 2.910991668701172,
      "learning_rate": 1.8688474472638335e-05,
      "loss": 1.4426,
      "step": 11100
    },
    {
      "epoch": 1.14134311627433,
      "grad_norm": 3.076895236968994,
      "learning_rate": 1.85865688372567e-05,
      "loss": 1.3961,
      "step": 11200
    },
    {
      "epoch": 1.1515336798124935,
      "grad_norm": 4.5148701667785645,
      "learning_rate": 1.8484663201875065e-05,
      "loss": 1.4453,
      "step": 11300
    },
    {
      "epoch": 1.1617242433506574,
      "grad_norm": 5.065725326538086,
      "learning_rate": 1.8382757566493428e-05,
      "loss": 1.4244,
      "step": 11400
    },
    {
      "epoch": 1.171914806888821,
      "grad_norm": 6.902016639709473,
      "learning_rate": 1.828085193111179e-05,
      "loss": 1.398,
      "step": 11500
    },
    {
      "epoch": 1.171914806888821,
      "eval_loss": 1.2245891094207764,
      "eval_runtime": 199.7772,
      "eval_samples_per_second": 17.339,
      "eval_steps_per_second": 8.67,
      "step": 11500
    },
    {
      "epoch": 1.1821053704269846,
      "grad_norm": 3.3813869953155518,
      "learning_rate": 1.8178946295730155e-05,
      "loss": 1.4817,
      "step": 11600
    },
    {
      "epoch": 1.1922959339651482,
      "grad_norm": 3.3772315979003906,
      "learning_rate": 1.8077040660348515e-05,
      "loss": 1.4924,
      "step": 11700
    },
    {
      "epoch": 1.2024864975033118,
      "grad_norm": 4.236727237701416,
      "learning_rate": 1.797513502496688e-05,
      "loss": 1.422,
      "step": 11800
    },
    {
      "epoch": 1.2126770610414757,
      "grad_norm": 2.5937893390655518,
      "learning_rate": 1.7873229389585245e-05,
      "loss": 1.4047,
      "step": 11900
    },
    {
      "epoch": 1.2228676245796393,
      "grad_norm": 3.28621244430542,
      "learning_rate": 1.7771323754203608e-05,
      "loss": 1.3691,
      "step": 12000
    },
    {
      "epoch": 1.2228676245796393,
      "eval_loss": 1.2336848974227905,
      "eval_runtime": 200.3037,
      "eval_samples_per_second": 17.294,
      "eval_steps_per_second": 8.647,
      "step": 12000
    },
    {
      "epoch": 1.2330581881178029,
      "grad_norm": 2.553321361541748,
      "learning_rate": 1.766941811882197e-05,
      "loss": 1.4149,
      "step": 12100
    },
    {
      "epoch": 1.2432487516559665,
      "grad_norm": 10.027904510498047,
      "learning_rate": 1.7567512483440335e-05,
      "loss": 1.4294,
      "step": 12200
    },
    {
      "epoch": 1.25343931519413,
      "grad_norm": 2.570755958557129,
      "learning_rate": 1.7465606848058698e-05,
      "loss": 1.5027,
      "step": 12300
    },
    {
      "epoch": 1.263629878732294,
      "grad_norm": 3.278454303741455,
      "learning_rate": 1.736370121267706e-05,
      "loss": 1.458,
      "step": 12400
    },
    {
      "epoch": 1.2738204422704575,
      "grad_norm": 3.0171589851379395,
      "learning_rate": 1.7261795577295425e-05,
      "loss": 1.4071,
      "step": 12500
    },
    {
      "epoch": 1.2738204422704575,
      "eval_loss": 1.2209100723266602,
      "eval_runtime": 200.9358,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 8.62,
      "step": 12500
    },
    {
      "epoch": 1.2840110058086212,
      "grad_norm": 4.5730881690979,
      "learning_rate": 1.7159889941913788e-05,
      "loss": 1.5265,
      "step": 12600
    },
    {
      "epoch": 1.294201569346785,
      "grad_norm": 3.4026074409484863,
      "learning_rate": 1.705798430653215e-05,
      "loss": 1.4617,
      "step": 12700
    },
    {
      "epoch": 1.3043921328849486,
      "grad_norm": 2.3560714721679688,
      "learning_rate": 1.6956078671150515e-05,
      "loss": 1.4504,
      "step": 12800
    },
    {
      "epoch": 1.3145826964231122,
      "grad_norm": 2.3456461429595947,
      "learning_rate": 1.6854173035768878e-05,
      "loss": 1.4832,
      "step": 12900
    },
    {
      "epoch": 1.3247732599612758,
      "grad_norm": 3.073012113571167,
      "learning_rate": 1.6752267400387245e-05,
      "loss": 1.3938,
      "step": 13000
    },
    {
      "epoch": 1.3247732599612758,
      "eval_loss": 1.2270833253860474,
      "eval_runtime": 201.6679,
      "eval_samples_per_second": 17.177,
      "eval_steps_per_second": 8.588,
      "step": 13000
    },
    {
      "epoch": 1.3349638234994394,
      "grad_norm": 5.477739334106445,
      "learning_rate": 1.6650361765005605e-05,
      "loss": 1.4439,
      "step": 13100
    },
    {
      "epoch": 1.3451543870376033,
      "grad_norm": 2.5260555744171143,
      "learning_rate": 1.6548456129623968e-05,
      "loss": 1.3716,
      "step": 13200
    },
    {
      "epoch": 1.3553449505757669,
      "grad_norm": 2.216676950454712,
      "learning_rate": 1.644655049424233e-05,
      "loss": 1.4039,
      "step": 13300
    },
    {
      "epoch": 1.3655355141139305,
      "grad_norm": 2.7223873138427734,
      "learning_rate": 1.6344644858860695e-05,
      "loss": 1.4595,
      "step": 13400
    },
    {
      "epoch": 1.375726077652094,
      "grad_norm": 2.5102949142456055,
      "learning_rate": 1.6242739223479058e-05,
      "loss": 1.4518,
      "step": 13500
    },
    {
      "epoch": 1.375726077652094,
      "eval_loss": 1.214667797088623,
      "eval_runtime": 201.3437,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 8.602,
      "step": 13500
    },
    {
      "epoch": 1.3859166411902577,
      "grad_norm": 3.070023536682129,
      "learning_rate": 1.6140833588097425e-05,
      "loss": 1.3724,
      "step": 13600
    },
    {
      "epoch": 1.3961072047284215,
      "grad_norm": 5.842353820800781,
      "learning_rate": 1.6038927952715785e-05,
      "loss": 1.4751,
      "step": 13700
    },
    {
      "epoch": 1.4062977682665851,
      "grad_norm": 2.719259023666382,
      "learning_rate": 1.5937022317334148e-05,
      "loss": 1.4546,
      "step": 13800
    },
    {
      "epoch": 1.4164883318047488,
      "grad_norm": 2.194978952407837,
      "learning_rate": 1.583511668195251e-05,
      "loss": 1.4822,
      "step": 13900
    },
    {
      "epoch": 1.4266788953429126,
      "grad_norm": 2.8972208499908447,
      "learning_rate": 1.5733211046570875e-05,
      "loss": 1.5258,
      "step": 14000
    },
    {
      "epoch": 1.4266788953429126,
      "eval_loss": 1.2064175605773926,
      "eval_runtime": 200.7919,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 8.626,
      "step": 14000
    },
    {
      "epoch": 1.4368694588810762,
      "grad_norm": 4.2488555908203125,
      "learning_rate": 1.5631305411189238e-05,
      "loss": 1.4678,
      "step": 14100
    },
    {
      "epoch": 1.4470600224192398,
      "grad_norm": 2.288648843765259,
      "learning_rate": 1.5529399775807605e-05,
      "loss": 1.4407,
      "step": 14200
    },
    {
      "epoch": 1.4572505859574034,
      "grad_norm": 2.587615728378296,
      "learning_rate": 1.5427494140425968e-05,
      "loss": 1.4694,
      "step": 14300
    },
    {
      "epoch": 1.467441149495567,
      "grad_norm": 2.5686097145080566,
      "learning_rate": 1.5325588505044328e-05,
      "loss": 1.4636,
      "step": 14400
    },
    {
      "epoch": 1.4776317130337309,
      "grad_norm": 2.998544454574585,
      "learning_rate": 1.5223682869662692e-05,
      "loss": 1.3913,
      "step": 14500
    },
    {
      "epoch": 1.4776317130337309,
      "eval_loss": 1.2060518264770508,
      "eval_runtime": 201.5719,
      "eval_samples_per_second": 17.185,
      "eval_steps_per_second": 8.592,
      "step": 14500
    },
    {
      "epoch": 1.4878222765718945,
      "grad_norm": 2.4548134803771973,
      "learning_rate": 1.5121777234281055e-05,
      "loss": 1.422,
      "step": 14600
    },
    {
      "epoch": 1.498012840110058,
      "grad_norm": 3.3229777812957764,
      "learning_rate": 1.501987159889942e-05,
      "loss": 1.399,
      "step": 14700
    },
    {
      "epoch": 1.5082034036482217,
      "grad_norm": 2.2541661262512207,
      "learning_rate": 1.4917965963517783e-05,
      "loss": 1.442,
      "step": 14800
    },
    {
      "epoch": 1.5183939671863853,
      "grad_norm": 3.640695571899414,
      "learning_rate": 1.4816060328136145e-05,
      "loss": 1.5,
      "step": 14900
    },
    {
      "epoch": 1.5285845307245491,
      "grad_norm": 2.6724917888641357,
      "learning_rate": 1.471415469275451e-05,
      "loss": 1.3577,
      "step": 15000
    },
    {
      "epoch": 1.5285845307245491,
      "eval_loss": 1.2142071723937988,
      "eval_runtime": 201.0199,
      "eval_samples_per_second": 17.232,
      "eval_steps_per_second": 8.616,
      "step": 15000
    },
    {
      "epoch": 1.5387750942627128,
      "grad_norm": 3.545664072036743,
      "learning_rate": 1.4612249057372873e-05,
      "loss": 1.4423,
      "step": 15100
    },
    {
      "epoch": 1.5489656578008764,
      "grad_norm": 104.90357971191406,
      "learning_rate": 1.4510343421991237e-05,
      "loss": 1.5439,
      "step": 15200
    },
    {
      "epoch": 1.5591562213390402,
      "grad_norm": 7.277150630950928,
      "learning_rate": 1.44084377866096e-05,
      "loss": 1.4075,
      "step": 15300
    },
    {
      "epoch": 1.5693467848772036,
      "grad_norm": 3.9275786876678467,
      "learning_rate": 1.4306532151227963e-05,
      "loss": 1.4251,
      "step": 15400
    },
    {
      "epoch": 1.5795373484153674,
      "grad_norm": 4.462745666503906,
      "learning_rate": 1.4204626515846327e-05,
      "loss": 1.4663,
      "step": 15500
    },
    {
      "epoch": 1.5795373484153674,
      "eval_loss": 1.2061939239501953,
      "eval_runtime": 201.6441,
      "eval_samples_per_second": 17.179,
      "eval_steps_per_second": 8.589,
      "step": 15500
    },
    {
      "epoch": 1.589727911953531,
      "grad_norm": 2.8855602741241455,
      "learning_rate": 1.410272088046469e-05,
      "loss": 1.4355,
      "step": 15600
    },
    {
      "epoch": 1.5999184754916946,
      "grad_norm": 3.0141897201538086,
      "learning_rate": 1.4000815245083053e-05,
      "loss": 1.4534,
      "step": 15700
    },
    {
      "epoch": 1.6101090390298585,
      "grad_norm": 3.4975733757019043,
      "learning_rate": 1.3898909609701417e-05,
      "loss": 1.4,
      "step": 15800
    },
    {
      "epoch": 1.6202996025680219,
      "grad_norm": 3.76729679107666,
      "learning_rate": 1.379700397431978e-05,
      "loss": 1.4333,
      "step": 15900
    },
    {
      "epoch": 1.6304901661061857,
      "grad_norm": 3.1804327964782715,
      "learning_rate": 1.3695098338938143e-05,
      "loss": 1.4138,
      "step": 16000
    },
    {
      "epoch": 1.6304901661061857,
      "eval_loss": 1.203220009803772,
      "eval_runtime": 202.1576,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 8.568,
      "step": 16000
    },
    {
      "epoch": 1.6406807296443493,
      "grad_norm": 2.815943956375122,
      "learning_rate": 1.3593192703556507e-05,
      "loss": 1.4696,
      "step": 16100
    },
    {
      "epoch": 1.650871293182513,
      "grad_norm": 3.1883304119110107,
      "learning_rate": 1.3491287068174872e-05,
      "loss": 1.4951,
      "step": 16200
    },
    {
      "epoch": 1.6610618567206767,
      "grad_norm": 2.29194974899292,
      "learning_rate": 1.3389381432793233e-05,
      "loss": 1.4069,
      "step": 16300
    },
    {
      "epoch": 1.6712524202588404,
      "grad_norm": 6.129655361175537,
      "learning_rate": 1.3287475797411597e-05,
      "loss": 1.4288,
      "step": 16400
    },
    {
      "epoch": 1.681442983797004,
      "grad_norm": 3.076737880706787,
      "learning_rate": 1.3185570162029962e-05,
      "loss": 1.4542,
      "step": 16500
    },
    {
      "epoch": 1.681442983797004,
      "eval_loss": 1.2080038785934448,
      "eval_runtime": 202.512,
      "eval_samples_per_second": 17.105,
      "eval_steps_per_second": 8.553,
      "step": 16500
    },
    {
      "epoch": 1.6916335473351678,
      "grad_norm": 3.251619577407837,
      "learning_rate": 1.3083664526648323e-05,
      "loss": 1.4271,
      "step": 16600
    },
    {
      "epoch": 1.7018241108733312,
      "grad_norm": 2.704101085662842,
      "learning_rate": 1.2981758891266687e-05,
      "loss": 1.3849,
      "step": 16700
    },
    {
      "epoch": 1.712014674411495,
      "grad_norm": 3.0535261631011963,
      "learning_rate": 1.2879853255885052e-05,
      "loss": 1.4233,
      "step": 16800
    },
    {
      "epoch": 1.7222052379496586,
      "grad_norm": 3.7566263675689697,
      "learning_rate": 1.2777947620503413e-05,
      "loss": 1.403,
      "step": 16900
    },
    {
      "epoch": 1.7323958014878222,
      "grad_norm": 2.2097835540771484,
      "learning_rate": 1.2676041985121777e-05,
      "loss": 1.4373,
      "step": 17000
    },
    {
      "epoch": 1.7323958014878222,
      "eval_loss": 1.2090322971343994,
      "eval_runtime": 203.6163,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 8.506,
      "step": 17000
    },
    {
      "epoch": 1.742586365025986,
      "grad_norm": 2.8264122009277344,
      "learning_rate": 1.2574136349740142e-05,
      "loss": 1.5439,
      "step": 17100
    },
    {
      "epoch": 1.7527769285641495,
      "grad_norm": 2.693540334701538,
      "learning_rate": 1.2472230714358505e-05,
      "loss": 1.4973,
      "step": 17200
    },
    {
      "epoch": 1.7629674921023133,
      "grad_norm": 4.3233418464660645,
      "learning_rate": 1.2370325078976867e-05,
      "loss": 1.3694,
      "step": 17300
    },
    {
      "epoch": 1.773158055640477,
      "grad_norm": 3.3947861194610596,
      "learning_rate": 1.2268419443595232e-05,
      "loss": 1.3922,
      "step": 17400
    },
    {
      "epoch": 1.7833486191786405,
      "grad_norm": 4.219278812408447,
      "learning_rate": 1.2166513808213595e-05,
      "loss": 1.4296,
      "step": 17500
    },
    {
      "epoch": 1.7833486191786405,
      "eval_loss": 1.1957221031188965,
      "eval_runtime": 203.5161,
      "eval_samples_per_second": 17.021,
      "eval_steps_per_second": 8.51,
      "step": 17500
    },
    {
      "epoch": 1.7935391827168043,
      "grad_norm": 3.216604709625244,
      "learning_rate": 1.2064608172831957e-05,
      "loss": 1.4799,
      "step": 17600
    },
    {
      "epoch": 1.8037297462549677,
      "grad_norm": 11.219060897827148,
      "learning_rate": 1.1962702537450322e-05,
      "loss": 1.4529,
      "step": 17700
    },
    {
      "epoch": 1.8139203097931316,
      "grad_norm": 2.3660342693328857,
      "learning_rate": 1.1860796902068685e-05,
      "loss": 1.3976,
      "step": 17800
    },
    {
      "epoch": 1.8241108733312952,
      "grad_norm": 3.2880263328552246,
      "learning_rate": 1.1758891266687047e-05,
      "loss": 1.4745,
      "step": 17900
    },
    {
      "epoch": 1.8343014368694588,
      "grad_norm": 3.1469075679779053,
      "learning_rate": 1.1656985631305412e-05,
      "loss": 1.3293,
      "step": 18000
    },
    {
      "epoch": 1.8343014368694588,
      "eval_loss": 1.1979666948318481,
      "eval_runtime": 205.0073,
      "eval_samples_per_second": 16.897,
      "eval_steps_per_second": 8.448,
      "step": 18000
    },
    {
      "epoch": 1.8444920004076226,
      "grad_norm": 3.134064197540283,
      "learning_rate": 1.1555079995923775e-05,
      "loss": 1.519,
      "step": 18100
    },
    {
      "epoch": 1.8546825639457862,
      "grad_norm": 2.773073434829712,
      "learning_rate": 1.1453174360542138e-05,
      "loss": 1.4029,
      "step": 18200
    },
    {
      "epoch": 1.8648731274839498,
      "grad_norm": 2.954782247543335,
      "learning_rate": 1.1351268725160502e-05,
      "loss": 1.4303,
      "step": 18300
    },
    {
      "epoch": 1.8750636910221137,
      "grad_norm": 2.470346212387085,
      "learning_rate": 1.1249363089778865e-05,
      "loss": 1.4192,
      "step": 18400
    },
    {
      "epoch": 1.885254254560277,
      "grad_norm": 2.40605092048645,
      "learning_rate": 1.1147457454397228e-05,
      "loss": 1.4912,
      "step": 18500
    },
    {
      "epoch": 1.885254254560277,
      "eval_loss": 1.1852672100067139,
      "eval_runtime": 203.7267,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 8.502,
      "step": 18500
    },
    {
      "epoch": 1.895444818098441,
      "grad_norm": 3.418362617492676,
      "learning_rate": 1.1045551819015592e-05,
      "loss": 1.4115,
      "step": 18600
    },
    {
      "epoch": 1.9056353816366045,
      "grad_norm": 3.5630314350128174,
      "learning_rate": 1.0943646183633955e-05,
      "loss": 1.3647,
      "step": 18700
    },
    {
      "epoch": 1.9158259451747681,
      "grad_norm": 3.1107568740844727,
      "learning_rate": 1.0841740548252318e-05,
      "loss": 1.376,
      "step": 18800
    },
    {
      "epoch": 1.926016508712932,
      "grad_norm": 3.3990707397460938,
      "learning_rate": 1.0739834912870682e-05,
      "loss": 1.4771,
      "step": 18900
    },
    {
      "epoch": 1.9362070722510953,
      "grad_norm": 4.028453826904297,
      "learning_rate": 1.0637929277489045e-05,
      "loss": 1.3425,
      "step": 19000
    },
    {
      "epoch": 1.9362070722510953,
      "eval_loss": 1.2038887739181519,
      "eval_runtime": 204.8553,
      "eval_samples_per_second": 16.909,
      "eval_steps_per_second": 8.455,
      "step": 19000
    },
    {
      "epoch": 1.9463976357892592,
      "grad_norm": 3.029521942138672,
      "learning_rate": 1.0536023642107408e-05,
      "loss": 1.4685,
      "step": 19100
    },
    {
      "epoch": 1.9565881993274228,
      "grad_norm": 4.317575931549072,
      "learning_rate": 1.0434118006725773e-05,
      "loss": 1.384,
      "step": 19200
    },
    {
      "epoch": 1.9667787628655864,
      "grad_norm": 3.1251089572906494,
      "learning_rate": 1.0332212371344135e-05,
      "loss": 1.4065,
      "step": 19300
    },
    {
      "epoch": 1.9769693264037502,
      "grad_norm": 3.122405529022217,
      "learning_rate": 1.0230306735962498e-05,
      "loss": 1.3695,
      "step": 19400
    },
    {
      "epoch": 1.9871598899419138,
      "grad_norm": 2.6719248294830322,
      "learning_rate": 1.0128401100580863e-05,
      "loss": 1.3949,
      "step": 19500
    },
    {
      "epoch": 1.9871598899419138,
      "eval_loss": 1.1976648569107056,
      "eval_runtime": 205.5901,
      "eval_samples_per_second": 16.849,
      "eval_steps_per_second": 8.425,
      "step": 19500
    },
    {
      "epoch": 1.9973504534800774,
      "grad_norm": 3.247211217880249,
      "learning_rate": 1.0026495465199225e-05,
      "loss": 1.3866,
      "step": 19600
    },
    {
      "epoch": 2.0075410170182413,
      "grad_norm": 3.2554242610931396,
      "learning_rate": 9.924589829817588e-06,
      "loss": 1.4726,
      "step": 19700
    },
    {
      "epoch": 2.0177315805564047,
      "grad_norm": 2.697312116622925,
      "learning_rate": 9.822684194435954e-06,
      "loss": 1.511,
      "step": 19800
    },
    {
      "epoch": 2.0279221440945685,
      "grad_norm": 4.495213508605957,
      "learning_rate": 9.720778559054315e-06,
      "loss": 1.4385,
      "step": 19900
    },
    {
      "epoch": 2.038112707632732,
      "grad_norm": 2.9091458320617676,
      "learning_rate": 9.618872923672678e-06,
      "loss": 1.4254,
      "step": 20000
    },
    {
      "epoch": 2.038112707632732,
      "eval_loss": 1.199669361114502,
      "eval_runtime": 205.5189,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 8.427,
      "step": 20000
    },
    {
      "epoch": 2.0483032711708957,
      "grad_norm": 2.2258763313293457,
      "learning_rate": 9.516967288291044e-06,
      "loss": 1.4317,
      "step": 20100
    },
    {
      "epoch": 2.0584938347090596,
      "grad_norm": 3.5074269771575928,
      "learning_rate": 9.415061652909407e-06,
      "loss": 1.4584,
      "step": 20200
    },
    {
      "epoch": 2.068684398247223,
      "grad_norm": 3.8856537342071533,
      "learning_rate": 9.313156017527768e-06,
      "loss": 1.4028,
      "step": 20300
    },
    {
      "epoch": 2.0788749617853868,
      "grad_norm": 3.0016491413116455,
      "learning_rate": 9.211250382146134e-06,
      "loss": 1.3624,
      "step": 20400
    },
    {
      "epoch": 2.0890655253235506,
      "grad_norm": 2.633639335632324,
      "learning_rate": 9.109344746764497e-06,
      "loss": 1.5093,
      "step": 20500
    },
    {
      "epoch": 2.0890655253235506,
      "eval_loss": 1.1918039321899414,
      "eval_runtime": 204.7485,
      "eval_samples_per_second": 16.918,
      "eval_steps_per_second": 8.459,
      "step": 20500
    },
    {
      "epoch": 2.099256088861714,
      "grad_norm": 3.387533664703369,
      "learning_rate": 9.007439111382859e-06,
      "loss": 1.3163,
      "step": 20600
    },
    {
      "epoch": 2.109446652399878,
      "grad_norm": 3.1177892684936523,
      "learning_rate": 8.905533476001224e-06,
      "loss": 1.515,
      "step": 20700
    },
    {
      "epoch": 2.119637215938041,
      "grad_norm": 2.739163398742676,
      "learning_rate": 8.803627840619587e-06,
      "loss": 1.3863,
      "step": 20800
    },
    {
      "epoch": 2.129827779476205,
      "grad_norm": 2.559671401977539,
      "learning_rate": 8.701722205237949e-06,
      "loss": 1.485,
      "step": 20900
    },
    {
      "epoch": 2.140018343014369,
      "grad_norm": 2.432347536087036,
      "learning_rate": 8.599816569856314e-06,
      "loss": 1.4217,
      "step": 21000
    },
    {
      "epoch": 2.140018343014369,
      "eval_loss": 1.1894869804382324,
      "eval_runtime": 204.6285,
      "eval_samples_per_second": 16.928,
      "eval_steps_per_second": 8.464,
      "step": 21000
    },
    {
      "epoch": 2.1502089065525323,
      "grad_norm": 2.6028380393981934,
      "learning_rate": 8.497910934474677e-06,
      "loss": 1.4299,
      "step": 21100
    },
    {
      "epoch": 2.160399470090696,
      "grad_norm": 2.6168787479400635,
      "learning_rate": 8.39600529909304e-06,
      "loss": 1.4526,
      "step": 21200
    },
    {
      "epoch": 2.1705900336288595,
      "grad_norm": 3.216635227203369,
      "learning_rate": 8.294099663711404e-06,
      "loss": 1.34,
      "step": 21300
    },
    {
      "epoch": 2.1807805971670233,
      "grad_norm": 2.087301015853882,
      "learning_rate": 8.192194028329767e-06,
      "loss": 1.4393,
      "step": 21400
    },
    {
      "epoch": 2.190971160705187,
      "grad_norm": 3.3502590656280518,
      "learning_rate": 8.09028839294813e-06,
      "loss": 1.378,
      "step": 21500
    },
    {
      "epoch": 2.190971160705187,
      "eval_loss": 1.1973501443862915,
      "eval_runtime": 205.6094,
      "eval_samples_per_second": 16.847,
      "eval_steps_per_second": 8.424,
      "step": 21500
    },
    {
      "epoch": 2.2011617242433505,
      "grad_norm": 2.2746176719665527,
      "learning_rate": 7.988382757566494e-06,
      "loss": 1.4174,
      "step": 21600
    },
    {
      "epoch": 2.2113522877815144,
      "grad_norm": 3.37005877494812,
      "learning_rate": 7.886477122184857e-06,
      "loss": 1.441,
      "step": 21700
    },
    {
      "epoch": 2.221542851319678,
      "grad_norm": 5.483434677124023,
      "learning_rate": 7.78457148680322e-06,
      "loss": 1.4069,
      "step": 21800
    },
    {
      "epoch": 2.2317334148578416,
      "grad_norm": 5.1183037757873535,
      "learning_rate": 7.682665851421584e-06,
      "loss": 1.4512,
      "step": 21900
    },
    {
      "epoch": 2.2419239783960054,
      "grad_norm": 4.820254802703857,
      "learning_rate": 7.580760216039947e-06,
      "loss": 1.4368,
      "step": 22000
    },
    {
      "epoch": 2.2419239783960054,
      "eval_loss": 1.1910661458969116,
      "eval_runtime": 204.97,
      "eval_samples_per_second": 16.9,
      "eval_steps_per_second": 8.45,
      "step": 22000
    },
    {
      "epoch": 2.252114541934169,
      "grad_norm": 3.2552249431610107,
      "learning_rate": 7.478854580658311e-06,
      "loss": 1.3732,
      "step": 22100
    },
    {
      "epoch": 2.2623051054723327,
      "grad_norm": 3.293207883834839,
      "learning_rate": 7.376948945276674e-06,
      "loss": 1.439,
      "step": 22200
    },
    {
      "epoch": 2.272495669010496,
      "grad_norm": 3.175931930541992,
      "learning_rate": 7.275043309895037e-06,
      "loss": 1.3965,
      "step": 22300
    },
    {
      "epoch": 2.28268623254866,
      "grad_norm": 3.017421245574951,
      "learning_rate": 7.173137674513401e-06,
      "loss": 1.3831,
      "step": 22400
    },
    {
      "epoch": 2.2928767960868237,
      "grad_norm": 3.9653289318084717,
      "learning_rate": 7.071232039131764e-06,
      "loss": 1.2972,
      "step": 22500
    },
    {
      "epoch": 2.2928767960868237,
      "eval_loss": 1.205815076828003,
      "eval_runtime": 205.822,
      "eval_samples_per_second": 16.83,
      "eval_steps_per_second": 8.415,
      "step": 22500
    },
    {
      "epoch": 2.303067359624987,
      "grad_norm": 3.887795925140381,
      "learning_rate": 6.969326403750128e-06,
      "loss": 1.3724,
      "step": 22600
    },
    {
      "epoch": 2.313257923163151,
      "grad_norm": 2.7628321647644043,
      "learning_rate": 6.867420768368491e-06,
      "loss": 1.4724,
      "step": 22700
    },
    {
      "epoch": 2.3234484867013148,
      "grad_norm": 2.4511642456054688,
      "learning_rate": 6.7655151329868545e-06,
      "loss": 1.4093,
      "step": 22800
    },
    {
      "epoch": 2.333639050239478,
      "grad_norm": 4.909644603729248,
      "learning_rate": 6.663609497605218e-06,
      "loss": 1.4917,
      "step": 22900
    },
    {
      "epoch": 2.343829613777642,
      "grad_norm": 3.9378490447998047,
      "learning_rate": 6.561703862223581e-06,
      "loss": 1.3841,
      "step": 23000
    },
    {
      "epoch": 2.343829613777642,
      "eval_loss": 1.1942780017852783,
      "eval_runtime": 205.0419,
      "eval_samples_per_second": 16.894,
      "eval_steps_per_second": 8.447,
      "step": 23000
    },
    {
      "epoch": 2.3540201773158054,
      "grad_norm": 2.8748085498809814,
      "learning_rate": 6.4597982268419445e-06,
      "loss": 1.3813,
      "step": 23100
    },
    {
      "epoch": 2.364210740853969,
      "grad_norm": 2.9527857303619385,
      "learning_rate": 6.357892591460308e-06,
      "loss": 1.431,
      "step": 23200
    },
    {
      "epoch": 2.374401304392133,
      "grad_norm": 2.470080852508545,
      "learning_rate": 6.255986956078672e-06,
      "loss": 1.3579,
      "step": 23300
    },
    {
      "epoch": 2.3845918679302964,
      "grad_norm": 3.261334180831909,
      "learning_rate": 6.1540813206970345e-06,
      "loss": 1.4698,
      "step": 23400
    },
    {
      "epoch": 2.3947824314684603,
      "grad_norm": 3.760899305343628,
      "learning_rate": 6.052175685315398e-06,
      "loss": 1.3993,
      "step": 23500
    },
    {
      "epoch": 2.3947824314684603,
      "eval_loss": 1.1864869594573975,
      "eval_runtime": 205.7376,
      "eval_samples_per_second": 16.837,
      "eval_steps_per_second": 8.418,
      "step": 23500
    },
    {
      "epoch": 2.4049729950066236,
      "grad_norm": 2.011866807937622,
      "learning_rate": 5.950270049933762e-06,
      "loss": 1.2826,
      "step": 23600
    },
    {
      "epoch": 2.4151635585447875,
      "grad_norm": 3.021008014678955,
      "learning_rate": 5.8483644145521245e-06,
      "loss": 1.3739,
      "step": 23700
    },
    {
      "epoch": 2.4253541220829513,
      "grad_norm": 3.0037989616394043,
      "learning_rate": 5.746458779170489e-06,
      "loss": 1.4,
      "step": 23800
    },
    {
      "epoch": 2.4355446856211147,
      "grad_norm": 2.86556077003479,
      "learning_rate": 5.644553143788852e-06,
      "loss": 1.3958,
      "step": 23900
    },
    {
      "epoch": 2.4457352491592785,
      "grad_norm": 3.904646873474121,
      "learning_rate": 5.5426475084072145e-06,
      "loss": 1.3256,
      "step": 24000
    },
    {
      "epoch": 2.4457352491592785,
      "eval_loss": 1.2011462450027466,
      "eval_runtime": 206.3622,
      "eval_samples_per_second": 16.786,
      "eval_steps_per_second": 8.393,
      "step": 24000
    },
    {
      "epoch": 2.4559258126974424,
      "grad_norm": 2.698688268661499,
      "learning_rate": 5.440741873025579e-06,
      "loss": 1.322,
      "step": 24100
    },
    {
      "epoch": 2.4661163762356058,
      "grad_norm": 2.292719602584839,
      "learning_rate": 5.338836237643942e-06,
      "loss": 1.4159,
      "step": 24200
    },
    {
      "epoch": 2.4763069397737696,
      "grad_norm": 1.8767633438110352,
      "learning_rate": 5.236930602262305e-06,
      "loss": 1.3556,
      "step": 24300
    },
    {
      "epoch": 2.486497503311933,
      "grad_norm": 2.611767292022705,
      "learning_rate": 5.135024966880669e-06,
      "loss": 1.3573,
      "step": 24400
    },
    {
      "epoch": 2.496688066850097,
      "grad_norm": 3.0535097122192383,
      "learning_rate": 5.033119331499032e-06,
      "loss": 1.3419,
      "step": 24500
    },
    {
      "epoch": 2.496688066850097,
      "eval_loss": 1.1974793672561646,
      "eval_runtime": 205.5637,
      "eval_samples_per_second": 16.851,
      "eval_steps_per_second": 8.426,
      "step": 24500
    },
    {
      "epoch": 2.50687863038826,
      "grad_norm": 3.6122639179229736,
      "learning_rate": 4.931213696117395e-06,
      "loss": 1.4596,
      "step": 24600
    },
    {
      "epoch": 2.517069193926424,
      "grad_norm": 2.8860654830932617,
      "learning_rate": 4.829308060735759e-06,
      "loss": 1.3814,
      "step": 24700
    },
    {
      "epoch": 2.527259757464588,
      "grad_norm": 2.4625754356384277,
      "learning_rate": 4.727402425354123e-06,
      "loss": 1.3,
      "step": 24800
    },
    {
      "epoch": 2.5374503210027513,
      "grad_norm": 2.1153340339660645,
      "learning_rate": 4.625496789972485e-06,
      "loss": 1.34,
      "step": 24900
    },
    {
      "epoch": 2.547640884540915,
      "grad_norm": 3.2748351097106934,
      "learning_rate": 4.523591154590849e-06,
      "loss": 1.4626,
      "step": 25000
    },
    {
      "epoch": 2.547640884540915,
      "eval_loss": 1.193760871887207,
      "eval_runtime": 206.4135,
      "eval_samples_per_second": 16.782,
      "eval_steps_per_second": 8.391,
      "step": 25000
    },
    {
      "epoch": 2.557831448079079,
      "grad_norm": 2.876289129257202,
      "learning_rate": 4.421685519209213e-06,
      "loss": 1.4154,
      "step": 25100
    },
    {
      "epoch": 2.5680220116172423,
      "grad_norm": 3.8943474292755127,
      "learning_rate": 4.3197798838275754e-06,
      "loss": 1.4281,
      "step": 25200
    },
    {
      "epoch": 2.578212575155406,
      "grad_norm": 3.412010669708252,
      "learning_rate": 4.21787424844594e-06,
      "loss": 1.4323,
      "step": 25300
    },
    {
      "epoch": 2.58840313869357,
      "grad_norm": 3.0277624130249023,
      "learning_rate": 4.115968613064303e-06,
      "loss": 1.3538,
      "step": 25400
    },
    {
      "epoch": 2.5985937022317334,
      "grad_norm": 3.5501396656036377,
      "learning_rate": 4.0140629776826654e-06,
      "loss": 1.4137,
      "step": 25500
    },
    {
      "epoch": 2.5985937022317334,
      "eval_loss": 1.1878149509429932,
      "eval_runtime": 207.531,
      "eval_samples_per_second": 16.691,
      "eval_steps_per_second": 8.346,
      "step": 25500
    },
    {
      "epoch": 2.608784265769897,
      "grad_norm": 2.834949254989624,
      "learning_rate": 3.91215734230103e-06,
      "loss": 1.3266,
      "step": 25600
    },
    {
      "epoch": 2.6189748293080606,
      "grad_norm": 2.8492014408111572,
      "learning_rate": 3.8102517069193925e-06,
      "loss": 1.4399,
      "step": 25700
    },
    {
      "epoch": 2.6291653928462244,
      "grad_norm": 4.040493011474609,
      "learning_rate": 3.708346071537756e-06,
      "loss": 1.3737,
      "step": 25800
    },
    {
      "epoch": 2.639355956384388,
      "grad_norm": 4.011177062988281,
      "learning_rate": 3.6064404361561196e-06,
      "loss": 1.4201,
      "step": 25900
    },
    {
      "epoch": 2.6495465199225516,
      "grad_norm": 2.5404422283172607,
      "learning_rate": 3.504534800774483e-06,
      "loss": 1.4007,
      "step": 26000
    },
    {
      "epoch": 2.6495465199225516,
      "eval_loss": 1.1882197856903076,
      "eval_runtime": 206.766,
      "eval_samples_per_second": 16.753,
      "eval_steps_per_second": 8.377,
      "step": 26000
    },
    {
      "epoch": 2.6597370834607155,
      "grad_norm": 2.9773294925689697,
      "learning_rate": 3.402629165392846e-06,
      "loss": 1.3898,
      "step": 26100
    },
    {
      "epoch": 2.669927646998879,
      "grad_norm": 3.631401538848877,
      "learning_rate": 3.3007235300112097e-06,
      "loss": 1.3654,
      "step": 26200
    },
    {
      "epoch": 2.6801182105370427,
      "grad_norm": 2.847015857696533,
      "learning_rate": 3.198817894629573e-06,
      "loss": 1.3463,
      "step": 26300
    },
    {
      "epoch": 2.6903087740752065,
      "grad_norm": 2.6816916465759277,
      "learning_rate": 3.0969122592479363e-06,
      "loss": 1.4028,
      "step": 26400
    },
    {
      "epoch": 2.70049933761337,
      "grad_norm": 2.567840337753296,
      "learning_rate": 2.9950066238663e-06,
      "loss": 1.377,
      "step": 26500
    },
    {
      "epoch": 2.70049933761337,
      "eval_loss": 1.1912901401519775,
      "eval_runtime": 206.9585,
      "eval_samples_per_second": 16.738,
      "eval_steps_per_second": 8.369,
      "step": 26500
    },
    {
      "epoch": 2.7106899011515337,
      "grad_norm": 2.513873815536499,
      "learning_rate": 2.8931009884846634e-06,
      "loss": 1.4025,
      "step": 26600
    },
    {
      "epoch": 2.7208804646896976,
      "grad_norm": 3.1115474700927734,
      "learning_rate": 2.7911953531030263e-06,
      "loss": 1.4892,
      "step": 26700
    },
    {
      "epoch": 2.731071028227861,
      "grad_norm": 2.2509713172912598,
      "learning_rate": 2.68928971772139e-06,
      "loss": 1.4746,
      "step": 26800
    },
    {
      "epoch": 2.741261591766025,
      "grad_norm": 2.469236373901367,
      "learning_rate": 2.5873840823397534e-06,
      "loss": 1.4313,
      "step": 26900
    },
    {
      "epoch": 2.751452155304188,
      "grad_norm": 2.3869171142578125,
      "learning_rate": 2.4854784469581168e-06,
      "loss": 1.3757,
      "step": 27000
    },
    {
      "epoch": 2.751452155304188,
      "eval_loss": 1.1900634765625,
      "eval_runtime": 205.3897,
      "eval_samples_per_second": 16.866,
      "eval_steps_per_second": 8.433,
      "step": 27000
    },
    {
      "epoch": 2.761642718842352,
      "grad_norm": 3.6013412475585938,
      "learning_rate": 2.3835728115764805e-06,
      "loss": 1.3991,
      "step": 27100
    },
    {
      "epoch": 2.7718332823805154,
      "grad_norm": 3.4102530479431152,
      "learning_rate": 2.2816671761948435e-06,
      "loss": 1.3731,
      "step": 27200
    },
    {
      "epoch": 2.7820238459186792,
      "grad_norm": 2.9903762340545654,
      "learning_rate": 2.179761540813207e-06,
      "loss": 1.3694,
      "step": 27300
    },
    {
      "epoch": 2.792214409456843,
      "grad_norm": 2.861806631088257,
      "learning_rate": 2.0778559054315706e-06,
      "loss": 1.3989,
      "step": 27400
    },
    {
      "epoch": 2.8024049729950065,
      "grad_norm": 2.104980230331421,
      "learning_rate": 1.975950270049934e-06,
      "loss": 1.426,
      "step": 27500
    },
    {
      "epoch": 2.8024049729950065,
      "eval_loss": 1.1875945329666138,
      "eval_runtime": 205.6578,
      "eval_samples_per_second": 16.844,
      "eval_steps_per_second": 8.422,
      "step": 27500
    },
    {
      "epoch": 2.8125955365331703,
      "grad_norm": 3.8184139728546143,
      "learning_rate": 1.8740446346682972e-06,
      "loss": 1.3733,
      "step": 27600
    },
    {
      "epoch": 2.822786100071334,
      "grad_norm": 2.52695631980896,
      "learning_rate": 1.7721389992866606e-06,
      "loss": 1.3678,
      "step": 27700
    },
    {
      "epoch": 2.8329766636094975,
      "grad_norm": 2.658346176147461,
      "learning_rate": 1.670233363905024e-06,
      "loss": 1.4032,
      "step": 27800
    },
    {
      "epoch": 2.8431672271476613,
      "grad_norm": 2.4607620239257812,
      "learning_rate": 1.5683277285233875e-06,
      "loss": 1.4341,
      "step": 27900
    },
    {
      "epoch": 2.853357790685825,
      "grad_norm": 2.3924577236175537,
      "learning_rate": 1.4664220931417506e-06,
      "loss": 1.4103,
      "step": 28000
    },
    {
      "epoch": 2.853357790685825,
      "eval_loss": 1.1903735399246216,
      "eval_runtime": 206.0958,
      "eval_samples_per_second": 16.808,
      "eval_steps_per_second": 8.404,
      "step": 28000
    },
    {
      "epoch": 2.8635483542239886,
      "grad_norm": 2.6382155418395996,
      "learning_rate": 1.3645164577601141e-06,
      "loss": 1.2432,
      "step": 28100
    },
    {
      "epoch": 2.8737389177621524,
      "grad_norm": 3.8874223232269287,
      "learning_rate": 1.2626108223784777e-06,
      "loss": 1.3771,
      "step": 28200
    },
    {
      "epoch": 2.883929481300316,
      "grad_norm": 3.8715567588806152,
      "learning_rate": 1.1607051869968408e-06,
      "loss": 1.3575,
      "step": 28300
    },
    {
      "epoch": 2.8941200448384796,
      "grad_norm": 3.8938169479370117,
      "learning_rate": 1.0587995516152044e-06,
      "loss": 1.4379,
      "step": 28400
    },
    {
      "epoch": 2.904310608376643,
      "grad_norm": 3.6944522857666016,
      "learning_rate": 9.56893916233568e-07,
      "loss": 1.3039,
      "step": 28500
    },
    {
      "epoch": 2.904310608376643,
      "eval_loss": 1.1908842325210571,
      "eval_runtime": 205.5243,
      "eval_samples_per_second": 16.854,
      "eval_steps_per_second": 8.427,
      "step": 28500
    },
    {
      "epoch": 2.914501171914807,
      "grad_norm": 3.294459581375122,
      "learning_rate": 8.549882808519311e-07,
      "loss": 1.3568,
      "step": 28600
    },
    {
      "epoch": 2.9246917354529707,
      "grad_norm": 2.649045705795288,
      "learning_rate": 7.530826454702945e-07,
      "loss": 1.3646,
      "step": 28700
    },
    {
      "epoch": 2.934882298991134,
      "grad_norm": 2.6787211894989014,
      "learning_rate": 6.511770100886579e-07,
      "loss": 1.5818,
      "step": 28800
    },
    {
      "epoch": 2.945072862529298,
      "grad_norm": 2.5964627265930176,
      "learning_rate": 5.492713747070214e-07,
      "loss": 1.428,
      "step": 28900
    },
    {
      "epoch": 2.9552634260674617,
      "grad_norm": 2.985262155532837,
      "learning_rate": 4.473657393253847e-07,
      "loss": 1.4519,
      "step": 29000
    },
    {
      "epoch": 2.9552634260674617,
      "eval_loss": 1.1874366998672485,
      "eval_runtime": 206.035,
      "eval_samples_per_second": 16.813,
      "eval_steps_per_second": 8.406,
      "step": 29000
    },
    {
      "epoch": 2.965453989605625,
      "grad_norm": 3.3430428504943848,
      "learning_rate": 3.454601039437481e-07,
      "loss": 1.3185,
      "step": 29100
    },
    {
      "epoch": 2.975644553143789,
      "grad_norm": 2.309440851211548,
      "learning_rate": 2.435544685621115e-07,
      "loss": 1.3837,
      "step": 29200
    },
    {
      "epoch": 2.985835116681953,
      "grad_norm": 3.1613776683807373,
      "learning_rate": 1.4164883318047488e-07,
      "loss": 1.3795,
      "step": 29300
    },
    {
      "epoch": 2.996025680220116,
      "grad_norm": 2.417023181915283,
      "learning_rate": 3.9743197798838275e-08,
      "loss": 1.292,
      "step": 29400
    }
  ],
  "logging_steps": 100,
  "max_steps": 29439,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.762565646122926e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
